{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.dom.minidom\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verify the integrity of images for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 4298, wrong: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "test_path = \"../../yolo_sc_20181128/test\"\n",
    "wrong_path = \"../../yolo_sc_20181128/wrong\"\n",
    "os.makedirs(wrong_path, exist_ok=True)\n",
    "\n",
    "img_names = [os.path.join(test_path, f) for f in os.listdir(test_path) if f.endswith(\".jpg\")]\n",
    "wrong = 0\n",
    "for img_name in img_names:\n",
    "    try:\n",
    "        img = Image.open(img_name)\n",
    "        img.close()\n",
    "    except:\n",
    "        wrong += 1\n",
    "        shutil.move(img_name, wrong_path)\n",
    "#         print(\"image corrupted\", img_name)\n",
    "print(\"total: {}, wrong: {}\".format(len(img_names), wrong))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pad test images to target sizes (608x608)\n",
    "#### image at its original size, usually much smaller, is not good for direct yolov3 prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def resize_img_with_padding(img_name, size, save_path):\n",
    "    img_name_new = os.path.join(save_path, os.path.basename(img_name))\n",
    "    txt_name_new = os.path.splitext(img_name_new)[0] + \".txt\"\n",
    "    \n",
    "    img = Image.open(img_name)\n",
    "    \n",
    "    # pad and crop image\n",
    "    x = -((size - img.size[0]) // 2)\n",
    "    y = -((size - img.size[1]) // 2)\n",
    "    img_croped = img.crop(\n",
    "        (\n",
    "            x,\n",
    "            y,\n",
    "            size + x,\n",
    "            size + y\n",
    "        )\n",
    "    )\n",
    "    img_croped.save(img_name_new)\n",
    "        \n",
    "    # write lables to txt\n",
    "    with open(txt_name_new, 'w') as f:\n",
    "        f.write(\"padx {} pady {}\\n\".format(x, y))\n",
    "            \n",
    "#     print(\"processed \", img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_path = \"../../yolo_sc_20181128/test\"\n",
    "test608_path = \"../../yolo_sc_20181128/test608\"\n",
    "size = 608\n",
    "\n",
    "os.makedirs(test608_path, exist_ok=True)\n",
    "img_names = [os.path.join(test_path, f) for f in os.listdir(test_path) if f.endswith(\".jpg\")]\n",
    "for img_name in img_names:\n",
    "    resize_img_with_padding(img_name, size, save_path=test608_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate xmls from prediction, jpg is not padded to target size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collect_labels(result_txt, class_i):\n",
    "    all_labels = {}\n",
    "    with open(result_txt, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            tokens = line.strip().rsplit(' ', 5)  # split from right, in case there is blank space in jpg name\n",
    "            basename = tokens[0]  # without file extension\n",
    "            det = float(tokens[1])\n",
    "            xmin, ymin = int(float(tokens[2])), int(float(tokens[3]))\n",
    "            xmax, ymax = int(float(tokens[4])), int(float(tokens[5]))\n",
    "            if not basename in all_labels:\n",
    "                all_labels[basename] = []\n",
    "            all_labels[basename].append({\"det\":det, \"xmin\":xmin, \"ymin\":ymin, \"xmax\":xmax, \"ymax\":ymax, \"name\":class_i})\n",
    "    return all_labels\n",
    "\n",
    "\n",
    "def generate_xml(basename, labels, data_path, save_path):\n",
    "    jpg_name = os.path.join(data_path, basename+\".jpg\")\n",
    "    with Image.open(jpg_name) as img:\n",
    "        w, h = img.size\n",
    "    \n",
    "    root = ET.Element(\"annotation\")\n",
    "    ET.SubElement(root, \"folder\").text = \"folder\"\n",
    "    ET.SubElement(root, \"filename\").text = basename + \".jpg\"\n",
    "    ET.SubElement(root, \"path\").text = \"path\"\n",
    "\n",
    "    source = ET.SubElement(root, \"source\")\n",
    "    ET.SubElement(source, \"database\").text = \"Unknown\"\n",
    "\n",
    "    size = ET.SubElement(root, \"size\")\n",
    "    ET.SubElement(size, \"width\").text = str(w)\n",
    "    ET.SubElement(size, \"height\").text = str(h)\n",
    "    ET.SubElement(size, \"depth\").text = \"3\"\n",
    "\n",
    "    ET.SubElement(root, \"segmented\").text = \"0\"\n",
    "\n",
    "    need_write = False\n",
    "    for label in labels:\n",
    "        if label[\"det\"] > 0.2:\n",
    "            need_write = True\n",
    "            object = ET.SubElement(root, \"object\")\n",
    "            ET.SubElement(object, \"name\").text = label[\"name\"]\n",
    "            ET.SubElement(object, \"pose\").text = \"Unspecified\"\n",
    "            ET.SubElement(object, \"truncated\").text = \"0\"\n",
    "            ET.SubElement(object, \"difficult\").text = \"0\"\n",
    "            bndbox = ET.SubElement(object, \"bndbox\")          \n",
    "            ET.SubElement(bndbox, \"xmin\").text = str(label[\"xmin\"])\n",
    "            ET.SubElement(bndbox, \"ymin\").text = str(label[\"ymin\"])\n",
    "            ET.SubElement(bndbox, \"xmax\").text = str(label[\"xmax\"])\n",
    "            ET.SubElement(bndbox, \"ymax\").text = str(label[\"ymax\"])\n",
    "\n",
    "    if not need_write:\n",
    "        return\n",
    "    raw_string = ET.tostring(root, \"utf-8\")\n",
    "    reparsed = xml.dom.minidom.parseString(raw_string)\n",
    "    with open(os.path.join(save_path, basename + \".xml\"), \"w\") as f:\n",
    "        f.write(reparsed.toprettyxml(indent=\"\\t\"))\n",
    "\n",
    "\n",
    "def main(result_txt, class_i, data_path, save_path):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    all_labels = collect_labels(result_txt, class_i)\n",
    "    for basename,labels in all_labels.items():\n",
    "        generate_xml(basename, labels, data_path, save_path)\n",
    "        print(\"generated\", basename+\".xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_txt = \"../../darknet/results/comp4_det_test_HSIL_S.txt\"\n",
    "class_i = \"HSIL_S\"\n",
    "data_path = \"../../yolo_hsil_s_20181128/test\"\n",
    "save_path = \"../../yolo_hsil_s_20181128/test_pred\"\n",
    "\n",
    "main(result_txt, class_i, data_path, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate xmls from prediction, jpg is padded to target size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collect_labels(result_txt, class_i):\n",
    "    all_labels = {}\n",
    "    with open(result_txt, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            tokens = line.strip().rsplit(' ', 5)  # split from right, in case there is blank space in jpg name\n",
    "            basename = tokens[0]  # without file extension\n",
    "            det = float(tokens[1])\n",
    "            xmin, ymin = int(float(tokens[2])), int(float(tokens[3]))\n",
    "            xmax, ymax = int(float(tokens[4])), int(float(tokens[5]))\n",
    "            if not basename in all_labels:\n",
    "                all_labels[basename] = []\n",
    "            all_labels[basename].append({\"det\":det, \"xmin\":xmin, \"ymin\":ymin, \"xmax\":xmax, \"ymax\":ymax, \"name\":class_i})\n",
    "    return all_labels\n",
    "\n",
    "\n",
    "def generate_xml_with_padding(basename, labels, orig_path, pad_path, save_path):\n",
    "    jpg_name = os.path.join(orig_path, basename+\".jpg\")\n",
    "    with Image.open(jpg_name) as img:\n",
    "        w, h = img.size\n",
    "    \n",
    "    pad_name = os.path.join(pad_path, basename+\".txt\")\n",
    "    with open(pad_name, 'r') as f:\n",
    "        line = f.readline()\n",
    "        tokens = line.strip().split()\n",
    "        padx, pady = int(tokens[1]), int(tokens[3])\n",
    "    \n",
    "    root = ET.Element(\"annotation\")\n",
    "    ET.SubElement(root, \"folder\").text = \"folder\"\n",
    "    ET.SubElement(root, \"filename\").text = basename + \".jpg\"\n",
    "    ET.SubElement(root, \"path\").text = \"path\"\n",
    "\n",
    "    source = ET.SubElement(root, \"source\")\n",
    "    ET.SubElement(source, \"database\").text = \"Unknown\"\n",
    "\n",
    "    size = ET.SubElement(root, \"size\")\n",
    "    ET.SubElement(size, \"width\").text = str(w)\n",
    "    ET.SubElement(size, \"height\").text = str(h)\n",
    "    ET.SubElement(size, \"depth\").text = \"3\"\n",
    "\n",
    "    ET.SubElement(root, \"segmented\").text = \"0\"\n",
    "\n",
    "    need_write = False\n",
    "    for label in labels:\n",
    "        if label[\"det\"] > 0.2:\n",
    "            need_write = True\n",
    "            object = ET.SubElement(root, \"object\")\n",
    "            ET.SubElement(object, \"name\").text = label[\"name\"]\n",
    "            ET.SubElement(object, \"pose\").text = \"Unspecified\"\n",
    "            ET.SubElement(object, \"truncated\").text = \"0\"\n",
    "            ET.SubElement(object, \"difficult\").text = \"0\"\n",
    "            bndbox = ET.SubElement(object, \"bndbox\")          \n",
    "            ET.SubElement(bndbox, \"xmin\").text = str(label[\"xmin\"]+padx)\n",
    "            ET.SubElement(bndbox, \"ymin\").text = str(label[\"ymin\"]+pady)\n",
    "            ET.SubElement(bndbox, \"xmax\").text = str(label[\"xmax\"]+padx)\n",
    "            ET.SubElement(bndbox, \"ymax\").text = str(label[\"ymax\"]+pady)\n",
    "\n",
    "    if not need_write:\n",
    "        return\n",
    "    raw_string = ET.tostring(root, \"utf-8\")\n",
    "    reparsed = xml.dom.minidom.parseString(raw_string)\n",
    "    with open(os.path.join(save_path, basename + \".xml\"), \"w\") as f:\n",
    "        f.write(reparsed.toprettyxml(indent=\"\\t\"))\n",
    "\n",
    "\n",
    "def main(result_txt, class_i, orig_path, pad_path, save_path):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    all_labels = collect_labels(result_txt, class_i)\n",
    "    for basename,labels in all_labels.items():\n",
    "        generate_xml_with_padding(basename, labels, orig_path, pad_path, save_path)\n",
    "        print(\"generated\", basename+\".xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_txt = \"../../darknet/results/comp4_det_test_HSIL_S.txt\"\n",
    "class_i = \"HSIL_S\"\n",
    "orig_path = \"../../yolo_hsil_s_20181128/test\"\n",
    "pad_path = \"../../yolo_hsil_s_20181128/test608\"\n",
    "save_path = \"../../yolo_hsil_s_20181128/test_pred\"\n",
    "\n",
    "main(result_txt, class_i, orig_path, pad_path, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

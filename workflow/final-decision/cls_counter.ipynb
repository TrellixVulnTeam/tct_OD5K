{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_path(dirpath):\n",
    "    files = [os.path.join(dirpath, filename) for filename in os.listdir(dirpath)]\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_count_for_2800(filepath):\n",
    "    result_lst = []\n",
    "    with open(filepath) as f:\n",
    "        lines = csv.reader(f)\n",
    "        next(lines, None)\n",
    "        for line in lines:\n",
    "            try:\n",
    "                mpp,area,patches,patch_i,patch_label,patch_probability,detect_label,detect_probability,classify_label,classify_probability,x,y,w,h = line\n",
    "                result_lst.append([detect_label,float(detect_probability),classify_label,float(classify_probability)])\n",
    "            except:\n",
    "                print(detect_label,detect_probability,classify_label,classify_probability)\n",
    "            \n",
    "    return result_lst\n",
    "            \n",
    "def read_and_count_for_1521(filepath):\n",
    "    result_lst = []\n",
    "    with open(filepath) as f:\n",
    "        lines = csv.reader(f)\n",
    "        next(lines, None)\n",
    "        for line in lines:\n",
    "            yolo_cell_class, yolo_cell_class_det, xcp_cell_class, xcp_cell_class_det, x, y, w, h, *_ = line\n",
    "            result_lst.append([yolo_cell_class, float(yolo_cell_class_det), xcp_cell_class, float(xcp_cell_class_det)])       \n",
    "            \n",
    "    return result_lst\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_and_count(lst, thresh):\n",
    "    dict_yolo = {}\n",
    "    dict_xcep = {}\n",
    "    \n",
    "    for item in lst:\n",
    "        yolo, yd, xcep, xd = item\n",
    "        if xd > thresh:\n",
    "            if xcep in dict_xcep:\n",
    "                dict_xcep[xcep] += 1\n",
    "            else:\n",
    "                dict_xcep[xcep] = 1\n",
    "                \n",
    "        if yd > thresh:\n",
    "            if yolo in dict_yolo:\n",
    "                dict_yolo[yolo] += 1\n",
    "            else:\n",
    "                dict_yolo[yolo] = 1\n",
    "                \n",
    "    return {\"detect\": dict_yolo, \"cls\": dict_xcep}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_2800 = [\"ACTINO\", \"AGC_A\", \"AGC_B\", \"ASCUS\", \"CC\", \"EC\", \"FUNGI\", \"GEC\", \"HSIL_B\", \"HSIL_M\", \"HSIL_S\", \"LSIL_E\", \"LSIL_F\", \"MC\", \"PH\", \"RC\", \"SC\", \"SCC_G\", \"SCC_R\", \"TRI\", \"VIRUS\"]\n",
    "classes_1521 = [\"ACTINO\", \"AGC_A\", \"AGC_B\", \"ASCUS\", \"CC\", \"EC\", \"CANDIDA\", \"GEC\", \"HSIL_B\", \"HSIL_M\", \"HSIL_S\", \"LSIL_E\", \"LSIL_F\", \"MC\", \"PH\", \"RC\", \"SC\", \"SCC_G\", \"SCC_R\", \"TRI\", \"HSV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write2csv(filename, header, lst):\n",
    "    with open(filename, \"w\", newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        # write headers\n",
    "        writer.writerow(header)\n",
    "\n",
    "        # write data\n",
    "        for line in lst:\n",
    "            writer.writerow(line)\n",
    "\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "   \n",
      "   \n",
      "   \n"
     ]
    }
   ],
   "source": [
    "gnet2_2800_files_dir = \"./gnet2/data2800\"\n",
    "files = get_files_path(gnet2_2800_files_dir)\n",
    "\n",
    "all = []\n",
    "for file in files:\n",
    "    lst = read_and_count_for_2800(file)\n",
    "    dict_ = cls_and_count(lst, 0)\n",
    "    lst = []\n",
    "    lst.append(os.path.basename(file))\n",
    "    for item in classes_2800:\n",
    "        cls = dict_[\"cls\"]\n",
    "        if item in cls:\n",
    "            lst.append(cls[item])\n",
    "        else:\n",
    "            lst.append(0)\n",
    "            \n",
    "    all.append(lst)\n",
    "    \n",
    "header = [\"name\"]\n",
    "header.extend(classes_2800)\n",
    "write2csv(\"gnet2_2800_count.csv\", header, all)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnet2_1521_files_dir = \"./gnet2/test1521\"\n",
    "files = get_files_path(gnet2_1521_files_dir)\n",
    "\n",
    "all = []\n",
    "for file in files:\n",
    "    lst = read_and_count_for_1521(file)\n",
    "    dict_ = cls_and_count(lst, 0)\n",
    "    lst = []\n",
    "    lst.append(os.path.basename(file))\n",
    "    for item in classes_1521:\n",
    "        cls = dict_[\"cls\"]\n",
    "        if item in cls:\n",
    "            lst.append(cls[item])\n",
    "        else:\n",
    "            lst.append(0)\n",
    "            \n",
    "    all.append(lst)\n",
    "    \n",
    "header = [\"name\"]\n",
    "header.extend(classes_1521)\n",
    "write2csv(\"gnet2_1521_count.csv\", header, all) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "   \n",
      "   \n"
     ]
    }
   ],
   "source": [
    "train15_2800_files_dir = \"./train15/data2800\"\n",
    "files = get_files_path(train15_2800_files_dir)\n",
    "\n",
    "all = []\n",
    "for file in files:\n",
    "    lst = read_and_count_for_2800(file)\n",
    "    dict_ = cls_and_count(lst, 0)\n",
    "    lst = []\n",
    "    lst.append(os.path.basename(file))\n",
    "    for item in classes_2800:\n",
    "        cls = dict_[\"cls\"]\n",
    "        if item in cls:\n",
    "            lst.append(cls[item])\n",
    "        else:\n",
    "            lst.append(0)\n",
    "            \n",
    "    all.append(lst)\n",
    "    \n",
    "header = [\"name\"]\n",
    "header.extend(classes_2800)\n",
    "write2csv(\"train15_2800_count.csv\", header, all) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train15_1521_files_dir = \"./train15/test1521\"\n",
    "files = get_files_path(train15_1521_files_dir)\n",
    "\n",
    "all = []\n",
    "for file in files:\n",
    "    lst = read_and_count_for_1521(file)\n",
    "    dict_ = cls_and_count(lst, 0)\n",
    "    lst = []\n",
    "    lst.append(os.path.basename(file))\n",
    "    for item in classes_1521:\n",
    "        cls = dict_[\"cls\"]\n",
    "        if item in cls:\n",
    "            lst.append(cls[item])\n",
    "        else:\n",
    "            lst.append(0)\n",
    "            \n",
    "    all.append(lst)\n",
    "    \n",
    "header = [\"name\"]\n",
    "header.extend(classes_1521)\n",
    "write2csv(\"train15_1521_count.csv\", header, all) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from multiprocessing import cpu_count\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR, SVC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerate = {\"AGC\":{\"AGC_A\", \"AGC_B\"}, \n",
    "            \"LSIL\":{\"ASCUS\", \"LSIL_E\", \"LSIL_F\"}, \n",
    "            \"ASCUS\":{\"ASCUS\", \"LSIL_E\", \"LSIL_F\"}, \n",
    "            \"HSIL-SCC_G\":{\"HSIL_B\", \"HSIL_M\", \"HSIL_S\", \"SCC_G\"}, \n",
    "            \"SCC_R\":{\"SCC_R\"}, \n",
    "            \"EC\":{\"EC\"}, \n",
    "            \"CC\":{\"CC\"}, \n",
    "            \"VIRUS\":{\"VIRUS\"}, \n",
    "            \"FUNGI\":{\"FUNGI\"}, \n",
    "            \"ACTINO\":{\"ACTINO\"}, \n",
    "            \"TRI\":{\"TRI\"}, \n",
    "            \"PH\":{\"PH\"}, \n",
    "            \"SC\":{\"SC\", \"RC\", \"MC\", \"GEC\"}}\n",
    "\n",
    "bin_imap = {0:'NILM', 1:'ABN'}\n",
    "all_imap = {0: 'ACTINO', 1: 'AGC', 2: 'ASCH', 3: 'ASCUS', 4: 'CC', 5: 'EC', 6: 'CANDIDA', \n",
    "            7: 'HSIL', 8: 'HSV', 9: 'LSIL', 10: 'NILM', 11: 'SCC', 12: 'TRI'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349 2340\n",
      "34 2340\n",
      "37 2340\n",
      "11 2340\n",
      "300 2340\n",
      "69 2340\n",
      "80 2340\n",
      "42 2340\n",
      "118 2340\n",
      "921 2340\n",
      "236 2340\n",
      "175 2340\n",
      "413 2340\n",
      "(1500, 2340)\n",
      "(1500, 2340)\n",
      "(1500, 2340)\n",
      "(1500, 2340)\n",
      "(1500, 2340)\n",
      "(1500, 2340)\n",
      "(1500, 2340)\n",
      "(1500, 2340)\n",
      "(1500, 2340)\n",
      "(1500, 2340)\n",
      "(1500, 2340)\n",
      "(1500, 2340)\n",
      "(1500, 2340)\n"
     ]
    }
   ],
   "source": [
    "# detect:0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9; \n",
    "# classify: 0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,0.99,0.999\n",
    "\n",
    "# with open('train15test1500.pkl', 'wb') as f:\n",
    "#     pickle.dump(X, f)\n",
    "#     pickle.dump(ya, f)\n",
    "#     pickle.dump(yb, f)\n",
    "#     pickle.dump(names, f)\n",
    "\n",
    "\n",
    "## 1. get data\n",
    "with open('gnet2data2800.pkl', 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "    ya = pickle.load(f)\n",
    "    yb = pickle.load(f)\n",
    "    names = pickle.load(f)\n",
    "    \n",
    "with open('header_imap.pkl', 'rb') as f:\n",
    "    idx = pickle.load(f)\n",
    "\n",
    "## 2. Do data augmentation\n",
    "\n",
    "# 2.1 environment setup\n",
    "\n",
    "label_cell = {'ACTINO':'ACTINO','AGC':'AGC','ASCUS':'ASCUS','CC':'CC','EC':'EC',\n",
    "              'CANDIDA':'FUNGI','HSIL':'HSIL-SCC_G','ASCH':'HSIL-SCC_G','LSIL':'LSIL',\n",
    "              'PH':'PH','NILM':'SC','SCC':'SCC_R','TRI':'TRI','HSV':'VIRUS'}\n",
    "\n",
    "label = ['ACTINO','AGC', 'ASCH', 'ASCUS','CC', 'EC', 'CANDIDA',\n",
    "            'HSIL', 'HSV','LSIL', 'NILM', 'SCC', 'TRI']\n",
    "\n",
    "\n",
    "det_score = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "cls_score = [0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,0.99,0.999]\n",
    "len_det_score = len(det_score)\n",
    "len_cls_score = len(cls_score) \n",
    "# _, cnts = np.unique(ya,return_counts=True)\n",
    "# print(cnts)\n",
    "# print(idx[(label[11], det_score[5], cls_score[8])])\n",
    "\n",
    "# 2.2 construct feature dictionary.\n",
    "feature_dict = {}\n",
    "\n",
    "for i in range(len(X)):\n",
    "    key = label[ya[i]]\n",
    "    if key in feature_dict:\n",
    "        feature_dict[key].append(X[i])\n",
    "    else:\n",
    "        feature_dict[key] = [X[i]]\n",
    "\n",
    "# 2.3 augmentation for one feature.\n",
    "def feature_aug(feature, key):\n",
    "    inc_num = randint(-2,8)\n",
    "    dec_num = randint(-8,2)\n",
    "    det_pos = randint(int(len(det_score)/2), len(det_score)-1)\n",
    "    cls_pos = randint(int(len(det_score)/2), len(det_score)-1)\n",
    "    if key == 'ASCH':\n",
    "#         inc_num  //= 5\n",
    "        pass\n",
    "    for i in range(det_pos)[::-1]:\n",
    "        for j in range(cls_pos)[::-1]:\n",
    "            cur_pos = idx[(key, det_score[i],cls_score[j])]\n",
    "            feature[cur_pos] += inc_num\n",
    "            feature[cur_pos+13*90] += inc_num\n",
    "            inc_num += randint(0,3)\n",
    "            for k in label:\n",
    "                if k == key:\n",
    "                    pass\n",
    "                cur_pos = idx[(key, det_score[i], cls_score[j])]\n",
    "                feature[cur_pos] = max(0, feature[cur_pos]+dec_num)\n",
    "                feature[cur_pos+13*90] = max(0, feature[cur_pos+13*90]+dec_num)\n",
    "    return feature\n",
    "            \n",
    "# 2.4 augmentation for all features.    \n",
    "aug_num_per_cls = 1500\n",
    "for key in feature_dict:\n",
    "    features = np.array(feature_dict[key])\n",
    "    feat_rows, feat_cols = features.shape\n",
    "    print(feat_rows, feat_cols)\n",
    "    for aug_num in range(aug_num_per_cls-feat_rows):\n",
    "        feature = features[randint(0,1000)%feat_rows]\n",
    "        feat_aug = feature_aug(feature, label_cell[key])\n",
    "        feature_dict[key].append(feat_aug)\n",
    "\n",
    "# for check \n",
    "for key in feature_dict:\n",
    "    features = np.array(feature_dict[key])\n",
    "    print(features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"feature_dict.pkl\", 'wb') as f:\n",
    "    pickle.dump(feature_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10)[::-1]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

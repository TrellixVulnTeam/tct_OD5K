{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "import xml.dom.minidom\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_files(directory, prefix=None, postfix=None):\n",
    "    files_list = []\n",
    "    for root, sub_dirs, files in os.walk(directory):\n",
    "        for special_file in files:\n",
    "            if postfix:\n",
    "                if special_file.endswith(postfix):\n",
    "                    files_list.append(os.path.join(root, special_file))\n",
    "            elif prefix:\n",
    "                if special_file.startswith(prefix):\n",
    "                    files_list.append(os.path.join(root, special_file))\n",
    "            else:\n",
    "                files_list.append(os.path.join(root, special_file))\n",
    "    return files_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### move jpgs with xmls/txts out to separate directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_jpg_and_labels(from_path, to_path):\n",
    "    image_names = scan_files(from_path, postfix=\".bmp\")\n",
    "    for image_name in image_names:\n",
    "        xml_name = os.path.splitext(image_name)[0] + \".xml\"\n",
    "        txt_name = os.path.splitext(image_name)[0] + \".txt\"\n",
    "        if os.path.isfile(xml_name):\n",
    "            shutil.move(image_name, to_path)\n",
    "            shutil.move(xml_name, to_path)\n",
    "        elif os.path.isfile(txt_name):\n",
    "            shutil.move(image_name, to_path)\n",
    "            shutil.move(txt_name, to_path)\n",
    "\n",
    "\n",
    "orig_path = \"../../yolo_sc_20181128/SC_orig\"\n",
    "tmp_path = \"../../yolo_sc_20181128/SC_tmp\"\n",
    "\n",
    "copy_jpg_and_labels(orig_path, tmp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find proper training input image size (608x608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all sizes of images\n",
    "tmp_path = \"../../yolo_hsil_s_20181128/hsil_s_all/HSIL_S_done\"\n",
    "image_names = [os.path.join(tmp_path, f) for f in os.listdir(tmp_path) if f.endswith(\".jpg\")]\n",
    "print(\"# of jpgs\", len(image_names))\n",
    "image_sizes = []\n",
    "for image_name in image_names:\n",
    "    with Image.open(image_name) as image:\n",
    "        image_sizes.append(image.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans clustering\n",
    "X = np.array(image_sizes)\n",
    "kmeans = KMeans(n_clusters=9, random_state=2018).fit(X)\n",
    "print(X.shape, kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = []\n",
    "for center in kmeans.cluster_centers_:\n",
    "    print(center)\n",
    "    centers.append(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(image_sizes)\n",
    "large = len([image_size for image_size in image_sizes if image_size[0] > 608 or image_size[1] > 608])\n",
    "print(total, large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image padding and resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels_from_xml(xml_name):\n",
    "    DOMTree = xml.dom.minidom.parse(xml_name)\n",
    "    collection = DOMTree.documentElement\n",
    "    filename = collection.getElementsByTagName(\"filename\")\n",
    "    objects = collection.getElementsByTagName(\"object\")\n",
    "\n",
    "    w = collection.getElementsByTagName(\"width\")[0]\n",
    "    w_val = int(w.firstChild.nodeValue)\n",
    "    h = collection.getElementsByTagName(\"height\")[0]\n",
    "    h_val = int(h.firstChild.nodeValue)\n",
    "    w.firstChild.replaceWholeText(str(h_val))\n",
    "    h.firstChild.replaceWholeText(str(w_val))\n",
    "\n",
    "    labels = {'w':w_val, 'h':h_val, 'boxes':[]}\n",
    "    \n",
    "    for object in objects:\n",
    "        xmin = object.getElementsByTagName(\"xmin\")[0]\n",
    "        xmin_val = int(xmin.firstChild.nodeValue)\n",
    "        xmax = object.getElementsByTagName(\"xmax\")[0]\n",
    "        xmax_val = int(xmax.firstChild.nodeValue)\n",
    "        ymin = object.getElementsByTagName(\"ymin\")[0]\n",
    "        ymin_val = int(ymin.firstChild.nodeValue)\n",
    "        ymax = object.getElementsByTagName(\"ymax\")[0]\n",
    "        ymax_val = int(ymax.firstChild.nodeValue)\n",
    "        labels[\"boxes\"].append([xmin_val, ymin_val, xmax_val, ymax_val])\n",
    "        \n",
    "    return labels\n",
    "\n",
    "\n",
    "def read_labels_from_txt(txt_name):\n",
    "    jpg_name = os.path.splitext(txt_name)[0] + \".bmp\"\n",
    "    with Image.open(jpg_name) as img:\n",
    "        w, h = img.size\n",
    "        \n",
    "    labels = {'w':w, 'h':h, 'boxes':[]}\n",
    "    with open(txt_name, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            tokens = line.strip().split()\n",
    "            xc, yc = w*float(tokens[1]), h*float(tokens[2])\n",
    "            w_, h_ = w*float(tokens[3]), h*float(tokens[4])\n",
    "            xmin, ymin = int(xc - w_/2), int(yc - h_/2)\n",
    "            xmax, ymax = int(xc + w_/2), int(yc + h_/2)\n",
    "            labels[\"boxes\"].append([xmin, ymin, xmax, ymax])\n",
    "            \n",
    "    return labels\n",
    "\n",
    "\n",
    "def get_labels_from_cell(img_name):\n",
    "    with Image.open(img_name) as img:\n",
    "        w, h = img.size\n",
    "        \n",
    "    labels = {'w':w, 'h':h, 'boxes':[[0, 0, w, h],]}\n",
    "    return labels\n",
    "\n",
    "\n",
    "def resize_img_with_padding(img_name, size, save_path):\n",
    "    xml_name = os.path.splitext(img_name)[0] + \".xml\"\n",
    "    txt_name = os.path.splitext(img_name)[0] + \".txt\"\n",
    "    if os.path.isfile(xml_name):\n",
    "        labels = read_labels_from_xml(xml_name)\n",
    "    elif os.path.isfile(txt_name):\n",
    "        labels = read_labels_from_txt(txt_name)\n",
    "    else:\n",
    "        labels = get_labels_from_cell(img_name)\n",
    "    \n",
    "    img_name_new = os.path.join(save_path, os.path.basename(img_name))\n",
    "    txt_name_new = os.path.splitext(img_name_new)[0] + \".txt\"\n",
    "    \n",
    "    img = Image.open(img_name)\n",
    "    \n",
    "    # pad and crop image\n",
    "    x = -((size - img.size[0]) // 2)\n",
    "    y = -((size - img.size[1]) // 2)\n",
    "    img_croped = img.crop(\n",
    "        (\n",
    "            x,\n",
    "            y,\n",
    "            size + x,\n",
    "            size + y\n",
    "        )\n",
    "    )\n",
    "    img_croped.save(img_name_new)\n",
    "\n",
    "    # change label coordinates\n",
    "    labels_yolo = []\n",
    "    for box in labels[\"boxes\"]:\n",
    "        xmin = box[0] - x\n",
    "        ymin = box[1] - y\n",
    "        xmax = box[2] - x\n",
    "        ymax = box[3] - y\n",
    "        xcenter = (xmin+xmax)/2.0/size\n",
    "        ycenter = (ymin+ymax)/2.0/size\n",
    "        w = (xmax-xmin)/size\n",
    "        h = (ymax-ymin)/size\n",
    "        labels_yolo.append(['0', str(xcenter), str(ycenter), str(w), str(h)])\n",
    "        \n",
    "#         # cut cells\n",
    "#         cell_name = os.path.splitext(img_name_new)[0] + '_' + str(xmin) + '_' + str(ymin) + \".jpg\"\n",
    "#         img_croped.crop((xmin, ymin, xmax, ymax)).save(cell_name)\n",
    "        \n",
    "    # write lables to txt\n",
    "    with open(txt_name_new, 'w') as f:\n",
    "        for label in labels_yolo:\n",
    "            f.write(' '.join(label) + '\\n')\n",
    "            \n",
    "#     print(\"processed \", img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# files 4793\n"
     ]
    }
   ],
   "source": [
    "tmp_path = \"/home/nvme/PH_train/PH\"\n",
    "yolo_path = \"/home/nvme/PH_train/PH-train\"\n",
    "size = 608\n",
    "\n",
    "image_names = scan_files(tmp_path, postfix=\".bmp\")\n",
    "print(\"# files\", len(image_names))\n",
    "os.makedirs(yolo_path, exist_ok=True)\n",
    "\n",
    "for image_name in image_names:\n",
    "    resize_img_with_padding(image_name, size, yolo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data into train/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "\n",
    "\n",
    "def split_train_valid(data_path):\n",
    "    img_names = [os.path.join(data_path, f) for f in os.listdir(data_path) if f.endswith(\".bmp\")]\n",
    "\n",
    "    random.shuffle(img_names)\n",
    "    random.shuffle(img_names)\n",
    "\n",
    "    split = 0.8\n",
    "\n",
    "    train_names = img_names[:int(len(img_names)*split)]\n",
    "    valid_names = img_names[int(len(img_names)*split):]\n",
    "\n",
    "    train_path = os.path.join(data_path, \"train\")\n",
    "    os.makedirs(train_path, exist_ok=True)\n",
    "    for img_name in train_names:\n",
    "        txt_name = os.path.splitext(img_name)[0] + \".txt\"\n",
    "        shutil.move(img_name, train_path)\n",
    "        shutil.move(txt_name, train_path)\n",
    "\n",
    "    valid_path = os.path.join(data_path, \"valid\")\n",
    "    os.makedirs(valid_path, exist_ok=True)\n",
    "    for img_name in valid_names:\n",
    "        txt_name = os.path.splitext(img_name)[0] + \".txt\"\n",
    "        shutil.move(img_name, valid_path)\n",
    "        shutil.move(txt_name, valid_path)\n",
    "        \n",
    "\n",
    "yolo_path = \"../../yolo_hsil_s_20181128/hsil_s_yolo\"\n",
    "split_train_valid(yolo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kmeans clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_files(directory, prefix=None, postfix=None):\n",
    "    files_list = []\n",
    "    for root, sub_dirs, files in os.walk(directory):\n",
    "        for special_file in files:\n",
    "            if postfix:\n",
    "                if special_file.endswith(postfix):\n",
    "                    files_list.append(os.path.join(root, special_file))\n",
    "            elif prefix:\n",
    "                if special_file.startswith(prefix):\n",
    "                    files_list.append(os.path.join(root, special_file))\n",
    "            else:\n",
    "                files_list.append(os.path.join(root, special_file))\n",
    "    return files_list\n",
    "\n",
    "def collect_sizes_from_yolotxt(txt_name, size):\n",
    "    sizes = []\n",
    "    with open(txt_name, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            tokens = line.strip().split()\n",
    "#             print(tokens)\n",
    "            w = int(float(tokens[3])*size)\n",
    "            h = int(float(tokens[4])*size)\n",
    "            sizes.append([w, h])\n",
    "    return sizes\n",
    "\n",
    "def collect_sizes_from_yolotxt_all(txt_names, size):\n",
    "    sizes = []\n",
    "    for txt_name in txt_names:\n",
    "        sizes += collect_sizes_from_yolotxt(txt_name, size)\n",
    "    return sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=9, n_init=10, n_jobs=None, precompute_distances='auto',\n",
      "    random_state=2018, tol=0.0001, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "yolo_path = \"/home/nvme/PH_train/PH-train\"\n",
    "size = 608\n",
    "\n",
    "sizes = collect_sizes_from_yolotxt_all(scan_files(yolo_path, postfix=\".txt\"), size)\n",
    "\n",
    "# kmeans clustering\n",
    "X = np.array(sizes)\n",
    "kmeans = KMeans(n_clusters=9, random_state=2018).fit(X)\n",
    "print(kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[127.64772727 161.71732955]\n",
      "[175.01140684 173.99746515]\n",
      "[189.97546012 225.25357873]\n",
      "[115.90107527 114.4516129 ]\n",
      "[245.31620553 247.50197628]\n",
      "[198.75       138.72477064]\n",
      "[157.09577465 135.03521127]\n",
      "[148.31234867 203.01210654]\n",
      "[222.85018727 184.62921348]\n"
     ]
    }
   ],
   "source": [
    "centers = []\n",
    "for center in kmeans.cluster_centers_:\n",
    "    print(center)\n",
    "    centers.append(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{13265: array([115.90107527, 114.4516129 ]), 20642: array([127.64772727, 161.71732955]), 30451: array([175.01140684, 173.99746515]), 30109: array([148.31234867, 203.01210654]), 42792: array([189.97546012, 225.25357873]), 41144: array([222.85018727, 184.62921348]), 60716: array([245.31620553, 247.50197628]), 27571: array([198.75      , 138.72477064]), 21213: array([157.09577465, 135.03521127])}\n"
     ]
    }
   ],
   "source": [
    "tosort = {int(center[0]*center[1]):center for center in centers}\n",
    "print(tosort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(13265, array([115.90107527, 114.4516129 ])), (20642, array([127.64772727, 161.71732955])), (21213, array([157.09577465, 135.03521127])), (27571, array([198.75      , 138.72477064])), (30109, array([148.31234867, 203.01210654])), (30451, array([175.01140684, 173.99746515])), (41144, array([222.85018727, 184.62921348])), (42792, array([189.97546012, 225.25357873])), (60716, array([245.31620553, 247.50197628]))]\n",
      "115,114,  127,161,  157,135,  198,138,  148,203,  175,173,  222,184,  189,225,  245,247\n"
     ]
    }
   ],
   "source": [
    "hassorted = sorted(tosort.items())\n",
    "print(hassorted)\n",
    "print(\",  \".join([\"{},{}\".format(int(value[1][0]),int(value[1][1])) for value in hassorted]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4793\n"
     ]
    }
   ],
   "source": [
    "print(len(sizes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cut cells from yolo images/txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def scan_files(directory, prefix=None, postfix=None):\n",
    "    files_list = []\n",
    "    for root, sub_dirs, files in os.walk(directory):\n",
    "        for special_file in files:\n",
    "            if postfix:\n",
    "                if special_file.endswith(postfix):\n",
    "                    files_list.append(os.path.join(root, special_file))\n",
    "            elif prefix:\n",
    "                if special_file.startswith(prefix):\n",
    "                    files_list.append(os.path.join(root, special_file))\n",
    "            else:\n",
    "                files_list.append(os.path.join(root, special_file))\n",
    "    return files_list\n",
    "\n",
    "def cut_cell(img_name, txt_name, save_path):\n",
    "    img = Image.open(img_name)\n",
    "    w,h = img.size\n",
    "    labels = []\n",
    "    with open(txt_name, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            tokens = line.strip().split()\n",
    "            cx, cy = float(tokens[1]), float(tokens[2])\n",
    "            w_, h_ = float(tokens[3]), float(tokens[4])\n",
    "            xmin, ymin = int((cx-w_/2)*w), int((cy-h_/2)*h)\n",
    "            xmax, ymax = int((cx+w_/2)*w), int((cy+h_/2)*h)\n",
    "            img.crop((xmin, ymin, xmax, ymax)).save(os.path.join(save_path, \"{}_{}_{}_{}.jpg\".format(xmin, ymin, xmax, ymax)))\n",
    "    img.close()\n",
    "    \n",
    "\n",
    "    \n",
    "image_dir = \"/home/hdd0/Develop/tct/point_detect_excess/TRI-deep-l-608/train\"\n",
    "save_path = \"/home/hdd0/Develop/tct/point_detect_excess/TRI-deep-l-608/cells\"\n",
    "\n",
    "img_names = scan_files(image_dir, postfix=\".bmp\")\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "for img_name in img_names:\n",
    "    txt_name = os.path.splitext(img_name)[0] + \".txt\"\n",
    "    cut_cell(img_name, txt_name, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove unwanted, small cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"/home/hdd0/Develop/tct/point_detect_excess/TRI-deep-l-608/train\"\n",
    "\n",
    "img_names = scan_files(image_dir, postfix=\".bmp\")\n",
    "for img_name in img_names:\n",
    "    txt_name = os.path.splitext(img_name)[0] + \".txt\"\n",
    "    xml_name = os.path.splitext(img_name)[0] + \".xml\"\n",
    "    to_delete = False\n",
    "    with open(txt_name, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            tokens = line.strip().split()\n",
    "            if float(tokens[3])*608 < 10 or float(tokens[4])*608 < 10:\n",
    "                to_delete = True\n",
    "    if to_delete:\n",
    "        os.remove(img_name)\n",
    "        os.remove(txt_name)\n",
    "        os.remove(xml_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

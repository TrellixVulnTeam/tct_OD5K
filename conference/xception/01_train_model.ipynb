{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import * \n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 20\n",
    "nb_gpus = 4\n",
    "image_size = (299, 299)\n",
    "input_shape= (299,299,3)\n",
    "\n",
    "train_path = \"/home/cnn/Documents/tct/conference/xception/batch6_cells_half299/train/\"\n",
    "valid_path = \"/home/cnn/Documents/tct/conference/xception/batch6_cells_half299/valid/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pretrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 74, 74, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 37, 37, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 37, 37, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 19, 19, 728)  186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 19, 19, 728)  2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 10, 10, 1024) 745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 10, 10, 1024) 4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 20)           40980       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,902,460\n",
      "Trainable params: 40,980\n",
      "Non-trainable params: 20,861,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    input_tensor = Input(input_shape)\n",
    "    x = Lambda(xception.preprocess_input)(input_tensor)\n",
    "\n",
    "    base_model = Xception(input_tensor=x, weights='imagenet', include_top=False)\n",
    "    m_out = base_model.output\n",
    "    p_out = GlobalAveragePooling2D()(m_out)\n",
    "    p_out = Dropout(0.5)(p_out)\n",
    "    predictions = Dense(nb_classes, activation='softmax', name=\"predictions\")(p_out)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "if nb_gpus > 1:\n",
    "    parallel_model = multi_gpu_model(model, gpus=nb_gpus)\n",
    "parallel_model.compile(optimizer='Adadelta', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 114939 images belonging to 20 classes.\n",
      "Found 12762 images belonging to 20 classes.\n",
      "Epoch 1/1\n",
      "1796/1796 [==============================] - 574s 320ms/step - loss: 1.3318 - acc: 0.6063 - val_loss: 2.3916 - val_acc: 0.3245\n"
     ]
    }
   ],
   "source": [
    "img_gen_t = ImageDataGenerator()\n",
    "train_generator = img_gen_t.flow_from_directory(train_path, \n",
    "                                                target_size=image_size, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "img_gen_v = ImageDataGenerator()\n",
    "valid_generator = img_gen_v.flow_from_directory(valid_path,\n",
    "                                                target_size=image_size, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "parallel_model.fit_generator(generator=train_generator, \n",
    "                             steps_per_epoch=len(train_generator), \n",
    "                             epochs=epochs, \n",
    "                             verbose=1,\n",
    "                             validation_data=valid_generator, \n",
    "                             validation_steps=len(valid_generator))\n",
    "\n",
    "model.save_weights(\"Xception_first_train.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 20)           20902460    lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Concatenate)       (None, 20)           0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "                                                                 model_1[3][0]                    \n",
      "                                                                 model_1[4][0]                    \n",
      "==================================================================================================\n",
      "Total params: 20,902,460\n",
      "Trainable params: 20,847,932\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(input_shape)\n",
    "x = Lambda(xception.preprocess_input)(input_tensor)\n",
    "\n",
    "base_model = Xception(input_tensor=x, weights=None, include_top=False)\n",
    "m_out = base_model.output\n",
    "p_out = GlobalAveragePooling2D()(m_out)\n",
    "p_out = Dropout(0.5)(p_out)\n",
    "predictions = Dense(nb_classes, activation='softmax', name=\"predictions\")(p_out)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "if nb_gpus > 1:\n",
    "    model = multi_gpu_model(model, gpus=nb_gpus)\n",
    "model.compile(optimizer='Adadelta', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights_026_0.1794.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 114939 images belonging to 20 classes.\n",
      "Found 12762 images belonging to 20 classes.\n",
      "Epoch 27/100\n",
      "1796/1796 [==============================] - 1166s 649ms/step - loss: 0.1222 - acc: 0.9537 - val_loss: 0.1824 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00027: saving model to weights_027_0.1824.hdf5\n",
      "Epoch 28/100\n",
      "1796/1796 [==============================] - 1129s 629ms/step - loss: 0.1179 - acc: 0.9551 - val_loss: 0.1745 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00028: saving model to weights_028_0.1745.hdf5\n",
      "Epoch 29/100\n",
      "1796/1796 [==============================] - 1130s 629ms/step - loss: 0.1193 - acc: 0.9553 - val_loss: 0.1933 - val_acc: 0.9372\n",
      "\n",
      "Epoch 00029: saving model to weights_029_0.1933.hdf5\n",
      "Epoch 30/100\n",
      "1796/1796 [==============================] - 1136s 633ms/step - loss: 0.1172 - acc: 0.9553 - val_loss: 0.1835 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00030: saving model to weights_030_0.1835.hdf5\n",
      "Epoch 31/100\n",
      "1796/1796 [==============================] - 1148s 639ms/step - loss: 0.1140 - acc: 0.9564 - val_loss: 0.1699 - val_acc: 0.9425\n",
      "\n",
      "Epoch 00031: saving model to weights_031_0.1699.hdf5\n",
      "Epoch 32/100\n",
      "1796/1796 [==============================] - 1147s 639ms/step - loss: 0.1133 - acc: 0.9570 - val_loss: 0.1826 - val_acc: 0.9388\n",
      "\n",
      "Epoch 00032: saving model to weights_032_0.1826.hdf5\n",
      "Epoch 33/100\n",
      "1796/1796 [==============================] - 1143s 637ms/step - loss: 0.1119 - acc: 0.9575 - val_loss: 0.1941 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00033: saving model to weights_033_0.1941.hdf5\n",
      "Epoch 34/100\n",
      "1796/1796 [==============================] - 1147s 639ms/step - loss: 0.1094 - acc: 0.9581 - val_loss: 0.1710 - val_acc: 0.9436\n",
      "\n",
      "Epoch 00034: saving model to weights_034_0.1710.hdf5\n",
      "Epoch 35/100\n",
      "1796/1796 [==============================] - 1148s 639ms/step - loss: 0.1103 - acc: 0.9585 - val_loss: 0.1905 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00035: saving model to weights_035_0.1905.hdf5\n",
      "Epoch 36/100\n",
      "1796/1796 [==============================] - 1145s 638ms/step - loss: 0.1062 - acc: 0.9600 - val_loss: 0.1876 - val_acc: 0.9337\n",
      "\n",
      "Epoch 00036: saving model to weights_036_0.1876.hdf5\n",
      "Epoch 37/100\n",
      "1796/1796 [==============================] - 1150s 640ms/step - loss: 0.1067 - acc: 0.9595 - val_loss: 0.1755 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00037: saving model to weights_037_0.1755.hdf5\n",
      "Epoch 38/100\n",
      "1796/1796 [==============================] - 1139s 634ms/step - loss: 0.1030 - acc: 0.9609 - val_loss: 0.2037 - val_acc: 0.9306\n",
      "\n",
      "Epoch 00038: saving model to weights_038_0.2037.hdf5\n",
      "Epoch 39/100\n",
      "1796/1796 [==============================] - 1152s 642ms/step - loss: 0.1026 - acc: 0.9608 - val_loss: 0.1869 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00039: saving model to weights_039_0.1869.hdf5\n",
      "Epoch 40/100\n",
      "1796/1796 [==============================] - 1147s 639ms/step - loss: 0.0992 - acc: 0.9623 - val_loss: 0.2068 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00040: saving model to weights_040_0.2068.hdf5\n",
      "Epoch 41/100\n",
      "1796/1796 [==============================] - 1155s 643ms/step - loss: 0.1012 - acc: 0.9612 - val_loss: 0.1727 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00041: saving model to weights_041_0.1727.hdf5\n",
      "Epoch 42/100\n",
      "1796/1796 [==============================] - 1152s 642ms/step - loss: 0.0995 - acc: 0.9626 - val_loss: 0.1991 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00042: saving model to weights_042_0.1991.hdf5\n",
      "Epoch 43/100\n",
      "1796/1796 [==============================] - 1152s 641ms/step - loss: 0.0969 - acc: 0.9636 - val_loss: 0.2210 - val_acc: 0.9330\n",
      "\n",
      "Epoch 00043: saving model to weights_043_0.2210.hdf5\n",
      "Epoch 44/100\n",
      "1796/1796 [==============================] - 1147s 639ms/step - loss: 0.0956 - acc: 0.9631 - val_loss: 0.1840 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00044: saving model to weights_044_0.1840.hdf5\n",
      "Epoch 45/100\n",
      "1796/1796 [==============================] - 1149s 640ms/step - loss: 0.0939 - acc: 0.9646 - val_loss: 0.2322 - val_acc: 0.9317\n",
      "\n",
      "Epoch 00045: saving model to weights_045_0.2322.hdf5\n",
      "Epoch 46/100\n",
      "1796/1796 [==============================] - 1143s 636ms/step - loss: 0.0935 - acc: 0.9651 - val_loss: 0.1997 - val_acc: 0.9366\n",
      "\n",
      "Epoch 00046: saving model to weights_046_0.1997.hdf5\n",
      "Epoch 47/100\n",
      "1796/1796 [==============================] - 1142s 636ms/step - loss: 0.0933 - acc: 0.9651 - val_loss: 0.1938 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00047: saving model to weights_047_0.1938.hdf5\n",
      "Epoch 48/100\n",
      "1796/1796 [==============================] - 1153s 642ms/step - loss: 0.0935 - acc: 0.9648 - val_loss: 0.2194 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00048: saving model to weights_048_0.2194.hdf5\n",
      "Epoch 49/100\n",
      "1796/1796 [==============================] - 1152s 641ms/step - loss: 0.0906 - acc: 0.9662 - val_loss: 0.1795 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00049: saving model to weights_049_0.1795.hdf5\n",
      "Epoch 50/100\n",
      "1796/1796 [==============================] - 1156s 644ms/step - loss: 0.0890 - acc: 0.9663 - val_loss: 0.1981 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00050: saving model to weights_050_0.1981.hdf5\n",
      "Epoch 51/100\n",
      "1796/1796 [==============================] - 1149s 640ms/step - loss: 0.0875 - acc: 0.9671 - val_loss: 0.1978 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00051: saving model to weights_051_0.1978.hdf5\n",
      "Epoch 52/100\n",
      "1796/1796 [==============================] - 1150s 641ms/step - loss: 0.0867 - acc: 0.9670 - val_loss: 0.1951 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00052: saving model to weights_052_0.1951.hdf5\n",
      "Epoch 53/100\n",
      "1796/1796 [==============================] - 1151s 641ms/step - loss: 0.0883 - acc: 0.9673 - val_loss: 0.2563 - val_acc: 0.9280\n",
      "\n",
      "Epoch 00053: saving model to weights_053_0.2563.hdf5\n",
      "Epoch 54/100\n",
      "1796/1796 [==============================] - 1151s 641ms/step - loss: 0.0851 - acc: 0.9680 - val_loss: 0.2487 - val_acc: 0.9346\n",
      "\n",
      "Epoch 00054: saving model to weights_054_0.2487.hdf5\n",
      "Epoch 55/100\n",
      "1796/1796 [==============================] - 1156s 644ms/step - loss: 0.0836 - acc: 0.9685 - val_loss: 0.2109 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00055: saving model to weights_055_0.2109.hdf5\n",
      "Epoch 56/100\n",
      "1796/1796 [==============================] - 1149s 640ms/step - loss: 0.0817 - acc: 0.9694 - val_loss: 0.2119 - val_acc: 0.9374\n",
      "\n",
      "Epoch 00056: saving model to weights_056_0.2119.hdf5\n",
      "Epoch 57/100\n",
      "1796/1796 [==============================] - 1150s 640ms/step - loss: 0.0809 - acc: 0.9686 - val_loss: 0.2125 - val_acc: 0.9373\n",
      "\n",
      "Epoch 00057: saving model to weights_057_0.2125.hdf5\n",
      "Epoch 58/100\n",
      "1796/1796 [==============================] - 1150s 640ms/step - loss: 0.0792 - acc: 0.9696 - val_loss: 0.1985 - val_acc: 0.9405\n",
      "\n",
      "Epoch 00058: saving model to weights_058_0.1985.hdf5\n",
      "Epoch 59/100\n",
      "1796/1796 [==============================] - 1145s 637ms/step - loss: 0.0792 - acc: 0.9703 - val_loss: 0.2482 - val_acc: 0.9346\n",
      "\n",
      "Epoch 00059: saving model to weights_059_0.2482.hdf5\n",
      "Epoch 60/100\n",
      "1796/1796 [==============================] - 1145s 637ms/step - loss: 0.0767 - acc: 0.9712 - val_loss: 0.2518 - val_acc: 0.9365\n",
      "\n",
      "Epoch 00060: saving model to weights_060_0.2518.hdf5\n",
      "Epoch 61/100\n",
      "1796/1796 [==============================] - 1151s 641ms/step - loss: 0.0751 - acc: 0.9723 - val_loss: 0.2189 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00061: saving model to weights_061_0.2189.hdf5\n",
      "Epoch 62/100\n",
      "1796/1796 [==============================] - 1155s 643ms/step - loss: 0.0749 - acc: 0.9722 - val_loss: 0.2248 - val_acc: 0.9394\n",
      "\n",
      "Epoch 00062: saving model to weights_062_0.2248.hdf5\n",
      "Epoch 63/100\n",
      "1796/1796 [==============================] - 1151s 641ms/step - loss: 0.0738 - acc: 0.9719 - val_loss: 0.2525 - val_acc: 0.9349\n",
      "\n",
      "Epoch 00063: saving model to weights_063_0.2525.hdf5\n",
      "Epoch 64/100\n",
      "1796/1796 [==============================] - 1148s 639ms/step - loss: 0.0747 - acc: 0.9721 - val_loss: 0.2922 - val_acc: 0.9265\n",
      "\n",
      "Epoch 00064: saving model to weights_064_0.2922.hdf5\n",
      "Epoch 65/100\n",
      "1796/1796 [==============================] - 1143s 636ms/step - loss: 0.0729 - acc: 0.9726 - val_loss: 0.2355 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00065: saving model to weights_065_0.2355.hdf5\n",
      "Epoch 66/100\n",
      "1796/1796 [==============================] - 1147s 639ms/step - loss: 0.0740 - acc: 0.9724 - val_loss: 0.2062 - val_acc: 0.9391\n",
      "\n",
      "Epoch 00066: saving model to weights_066_0.2062.hdf5\n",
      "Epoch 67/100\n",
      "1796/1796 [==============================] - 1150s 640ms/step - loss: 0.0723 - acc: 0.9730 - val_loss: 0.2049 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00067: saving model to weights_067_0.2049.hdf5\n",
      "Epoch 68/100\n",
      "1796/1796 [==============================] - 1148s 639ms/step - loss: 0.0699 - acc: 0.9738 - val_loss: 0.2296 - val_acc: 0.9351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00068: saving model to weights_068_0.2296.hdf5\n",
      "Epoch 69/100\n",
      "1796/1796 [==============================] - 1150s 640ms/step - loss: 0.0694 - acc: 0.9742 - val_loss: 0.1863 - val_acc: 0.9446\n",
      "\n",
      "Epoch 00069: saving model to weights_069_0.1863.hdf5\n",
      "Epoch 70/100\n",
      "1796/1796 [==============================] - 1140s 635ms/step - loss: 0.0705 - acc: 0.9738 - val_loss: 0.2445 - val_acc: 0.9355\n",
      "\n",
      "Epoch 00070: saving model to weights_070_0.2445.hdf5\n",
      "Epoch 71/100\n",
      "1796/1796 [==============================] - 1156s 643ms/step - loss: 0.0675 - acc: 0.9751 - val_loss: 0.2536 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00071: saving model to weights_071_0.2536.hdf5\n",
      "Epoch 72/100\n",
      "1796/1796 [==============================] - 1151s 641ms/step - loss: 0.0675 - acc: 0.9750 - val_loss: 0.2414 - val_acc: 0.9388\n",
      "\n",
      "Epoch 00072: saving model to weights_072_0.2414.hdf5\n",
      "Epoch 73/100\n",
      "1796/1796 [==============================] - 1136s 632ms/step - loss: 0.0677 - acc: 0.9754 - val_loss: 0.2301 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00073: saving model to weights_073_0.2301.hdf5\n",
      "Epoch 74/100\n",
      "1796/1796 [==============================] - 1140s 635ms/step - loss: 0.0663 - acc: 0.9754 - val_loss: 0.2308 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00074: saving model to weights_074_0.2308.hdf5\n",
      "Epoch 75/100\n",
      "1796/1796 [==============================] - 1152s 641ms/step - loss: 0.0644 - acc: 0.9759 - val_loss: 0.2855 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00075: saving model to weights_075_0.2855.hdf5\n",
      "Epoch 76/100\n",
      "1796/1796 [==============================] - 1154s 643ms/step - loss: 0.0638 - acc: 0.9760 - val_loss: 0.2183 - val_acc: 0.9426\n",
      "\n",
      "Epoch 00076: saving model to weights_076_0.2183.hdf5\n",
      "Epoch 77/100\n",
      "1796/1796 [==============================] - 1156s 644ms/step - loss: 0.0634 - acc: 0.9765 - val_loss: 0.2653 - val_acc: 0.9266\n",
      "\n",
      "Epoch 00077: saving model to weights_077_0.2653.hdf5\n",
      "Epoch 78/100\n",
      "1796/1796 [==============================] - 1160s 646ms/step - loss: 0.0608 - acc: 0.9778 - val_loss: 0.2496 - val_acc: 0.9298\n",
      "\n",
      "Epoch 00078: saving model to weights_078_0.2496.hdf5\n",
      "Epoch 79/100\n",
      "1796/1796 [==============================] - 1149s 640ms/step - loss: 0.0608 - acc: 0.9774 - val_loss: 0.2976 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00079: saving model to weights_079_0.2976.hdf5\n",
      "Epoch 80/100\n",
      "1796/1796 [==============================] - 1149s 640ms/step - loss: 0.0606 - acc: 0.9776 - val_loss: 0.2204 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00080: saving model to weights_080_0.2204.hdf5\n",
      "Epoch 81/100\n",
      "1796/1796 [==============================] - 1148s 639ms/step - loss: 0.0592 - acc: 0.9787 - val_loss: 0.2196 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00081: saving model to weights_081_0.2196.hdf5\n",
      "Epoch 82/100\n",
      "1796/1796 [==============================] - 1154s 643ms/step - loss: 0.0575 - acc: 0.9789 - val_loss: 0.2480 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00082: saving model to weights_082_0.2480.hdf5\n",
      "Epoch 83/100\n",
      "1796/1796 [==============================] - 1146s 638ms/step - loss: 0.0582 - acc: 0.9785 - val_loss: 0.2122 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00083: saving model to weights_083_0.2122.hdf5\n",
      "Epoch 84/100\n",
      "1796/1796 [==============================] - 1149s 640ms/step - loss: 0.0561 - acc: 0.9791 - val_loss: 0.2373 - val_acc: 0.9393\n",
      "\n",
      "Epoch 00084: saving model to weights_084_0.2373.hdf5\n",
      "Epoch 85/100\n",
      "1796/1796 [==============================] - 1150s 640ms/step - loss: 0.0556 - acc: 0.9794 - val_loss: 0.2150 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00085: saving model to weights_085_0.2150.hdf5\n",
      "Epoch 86/100\n",
      "1796/1796 [==============================] - 1152s 642ms/step - loss: 0.0564 - acc: 0.9793 - val_loss: 0.2083 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00086: saving model to weights_086_0.2083.hdf5\n",
      "Epoch 87/100\n",
      "1796/1796 [==============================] - 1160s 646ms/step - loss: 0.0551 - acc: 0.9801 - val_loss: 0.2293 - val_acc: 0.9443\n",
      "\n",
      "Epoch 00087: saving model to weights_087_0.2293.hdf5\n",
      "Epoch 88/100\n",
      "1796/1796 [==============================] - 1154s 642ms/step - loss: 0.0545 - acc: 0.9803 - val_loss: 0.2590 - val_acc: 0.9360\n",
      "\n",
      "Epoch 00088: saving model to weights_088_0.2590.hdf5\n",
      "Epoch 89/100\n",
      "1796/1796 [==============================] - 1150s 640ms/step - loss: 0.0537 - acc: 0.9800 - val_loss: 0.2273 - val_acc: 0.9381\n",
      "\n",
      "Epoch 00089: saving model to weights_089_0.2273.hdf5\n",
      "Epoch 90/100\n",
      "1796/1796 [==============================] - 1152s 641ms/step - loss: 0.0531 - acc: 0.9806 - val_loss: 0.2131 - val_acc: 0.9434\n",
      "\n",
      "Epoch 00090: saving model to weights_090_0.2131.hdf5\n",
      "Epoch 91/100\n",
      "1796/1796 [==============================] - 1154s 643ms/step - loss: 0.0535 - acc: 0.9806 - val_loss: 0.2583 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00091: saving model to weights_091_0.2583.hdf5\n",
      "Epoch 92/100\n",
      "1796/1796 [==============================] - 1152s 641ms/step - loss: 0.0516 - acc: 0.9813 - val_loss: 0.2433 - val_acc: 0.9408\n",
      "\n",
      "Epoch 00092: saving model to weights_092_0.2433.hdf5\n",
      "Epoch 93/100\n",
      "1796/1796 [==============================] - 1156s 644ms/step - loss: 0.0511 - acc: 0.9813 - val_loss: 0.2163 - val_acc: 0.9409\n",
      "\n",
      "Epoch 00093: saving model to weights_093_0.2163.hdf5\n",
      "Epoch 94/100\n",
      "1796/1796 [==============================] - 1162s 647ms/step - loss: 0.0510 - acc: 0.9814 - val_loss: 0.2447 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00094: saving model to weights_094_0.2447.hdf5\n",
      "Epoch 95/100\n",
      "1796/1796 [==============================] - 1158s 645ms/step - loss: 0.0499 - acc: 0.9818 - val_loss: 0.2764 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00095: saving model to weights_095_0.2764.hdf5\n",
      "Epoch 96/100\n",
      "1796/1796 [==============================] - 1150s 640ms/step - loss: 0.0523 - acc: 0.9814 - val_loss: 0.2478 - val_acc: 0.9414\n",
      "\n",
      "Epoch 00096: saving model to weights_096_0.2478.hdf5\n",
      "Epoch 97/100\n",
      "1796/1796 [==============================] - 1159s 645ms/step - loss: 0.0474 - acc: 0.9825 - val_loss: 0.2859 - val_acc: 0.9334\n",
      "\n",
      "Epoch 00097: saving model to weights_097_0.2859.hdf5\n",
      "Epoch 98/100\n",
      "1796/1796 [==============================] - 1155s 643ms/step - loss: 0.0490 - acc: 0.9824 - val_loss: 0.2825 - val_acc: 0.9319\n",
      "\n",
      "Epoch 00098: saving model to weights_098_0.2825.hdf5\n",
      "Epoch 99/100\n",
      "1796/1796 [==============================] - 1153s 642ms/step - loss: 0.0500 - acc: 0.9824 - val_loss: 0.2424 - val_acc: 0.9412\n",
      "\n",
      "Epoch 00099: saving model to weights_099_0.2424.hdf5\n",
      "Epoch 100/100\n",
      "1796/1796 [==============================] - 1155s 643ms/step - loss: 0.0459 - acc: 0.9831 - val_loss: 0.2667 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00100: saving model to weights_100_0.2667.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc4ac989d68>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "img_gen_t = ImageDataGenerator(rotation_range=90,                            \n",
    "                               width_shift_range=0.1,\n",
    "                               height_shift_range=0.1,\n",
    "                               zoom_range=0.1,\n",
    "                               brightness_range=[0.9, 1.1],\n",
    "#                               zca_whitening= True,\n",
    "                               horizontal_flip=True,\n",
    "                               vertical_flip=True)\n",
    "train_generator = img_gen_t.flow_from_directory(train_path, \n",
    "                                                target_size=image_size, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "img_gen_v = ImageDataGenerator()\n",
    "valid_generator = img_gen_v.flow_from_directory(valid_path,\n",
    "                                                target_size=image_size, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"weights_{epoch:03d}_{val_loss:.4f}.hdf5\", monitor='val_loss', verbose=1,\n",
    "                             save_best_only=False, save_weights_only=True, mode='min', period=1)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"./logs\", histogram_freq=0, batch_size=batch_size, write_graph=True, write_images=True)\n",
    "\n",
    "callbacks = [checkpoint, tensorboard]\n",
    "\n",
    "model.fit_generator(generator=train_generator, \n",
    "                    steps_per_epoch=len(train_generator), \n",
    "                    epochs=epochs, \n",
    "                    verbose=1,\n",
    "                    validation_data=valid_generator, \n",
    "                    validation_steps=len(valid_generator), \n",
    "                    callbacks=callbacks, \n",
    "                    workers=16, \n",
    "                    use_multiprocessing=True,\n",
    "                    initial_epoch=26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot training trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. first need to retrieve acc/loss/val_acc/val_loss info from tensorboard\n",
    "# in terminal: tensorboard --logdir ./logs\n",
    "# open browser with given link\n",
    "# save data to local csv and merge four separate files\n",
    "\n",
    "# 2. read from saved data csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv_file = \"./info_20181118.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "step = list(df.step)\n",
    "acc = list(df.acc)\n",
    "loss = list(df.loss)\n",
    "val_acc = list(df.val_acc)\n",
    "val_loss = list(df.val_loss)\n",
    "\n",
    "# 3. plot acc and loss\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "fig = plt.figure(1, figsize=(12,6), dpi=90)\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(step, acc,label=\"train\")\n",
    "ax.plot(step, val_acc,label=\"valid\")\n",
    "ax.legend()\n",
    "plt.title(\"training accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "ax = fig.add_subplot(122)\n",
    "ax.plot(step, loss,label=\"train\")\n",
    "ax.plot(step, val_loss,label=\"vaild\")\n",
    "ax.legend()\n",
    "plt.title(\"training loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

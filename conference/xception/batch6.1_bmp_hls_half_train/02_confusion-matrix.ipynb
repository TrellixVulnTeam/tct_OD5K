{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import * \n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from multiprocessing import cpu_count\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 20\n",
    "nb_cpus = cpu_count()//2\n",
    "nb_gpus = 4\n",
    "\n",
    "image_size = (299, 299)\n",
    "input_shape= (299, 299, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 20)           20902460    lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Concatenate)           (None, 20)           0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "                                                                 model_1[3][0]                    \n",
      "                                                                 model_1[4][0]                    \n",
      "==================================================================================================\n",
      "Total params: 20,902,460\n",
      "Trainable params: 20,847,932\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    input_tensor = Input(input_shape)\n",
    "    x = Lambda(xception.preprocess_input)(input_tensor)\n",
    "\n",
    "    base_model = Xception(input_tensor=x, weights=None, include_top=False)\n",
    "    m_out = base_model.output\n",
    "    p_out = GlobalAveragePooling2D()(m_out)\n",
    "    p_out = Dropout(1.0)(p_out)\n",
    "    predictions = Dense(nb_classes, activation='softmax')(p_out)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "model = multi_gpu_model(model, gpus=nb_gpus)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights_010_0.0698.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38043 images belonging to 20 classes.\n",
      "298/298 [==============================] - 470s 2s/step\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "test_path = \"/home/cnn/Documents/batch6.1_bmp/train1/valid\"\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "test_generator = gen.flow_from_directory(test_path, \n",
    "                                         target_size=image_size, \n",
    "                                         shuffle=False,\n",
    "                                         batch_size=batch_size)\n",
    "test_img_nums = test_generator.samples\n",
    "all_test_results = model.predict_generator(test_generator, \n",
    "                                           len(test_generator), \n",
    "                                           workers=nb_cpus, \n",
    "                                           use_multiprocessing=True,\n",
    "                                           verbose=1)\n",
    "all_labels = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MC': 13, 'SCC_G': 16, 'ASCUS': 3, 'SCC_R': 17, 'LSIL_F': 12, 'AGC_B': 2, 'LSIL_E': 11, 'EC': 5, 'HSIL_M': 9, 'FUNGI': 6, 'RC': 14, 'VIRUS': 19, 'TRI': 18, 'CC': 4, 'HSIL_S': 10, 'ACTINO': 0, 'GEC': 7, 'HSIL_B': 8, 'AGC_A': 1, 'SC': 15}\n"
     ]
    }
   ],
   "source": [
    "class_label_dict = test_generator.class_indices\n",
    "print(test_generator.class_indices)\n",
    "def get_key(dict_, value):\n",
    "    return [k for k, v in dict_.items() if v == value]\n",
    "\n",
    "# create class num lens dict, every dict store current class predict num\n",
    "total_predictions_dict = {}\n",
    "for row_class_name, label in class_label_dict.items():\n",
    "    total_predictions_dict[row_class_name] = {}\n",
    "    for column_class_name, label in class_label_dict.items():\n",
    "        total_predictions_dict[row_class_name][column_class_name] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.95\n",
    "\n",
    "for i, label in enumerate(all_labels):\n",
    "    predict_index = np.argmax(all_test_results[i])\n",
    "    predict_det = all_test_results[i][predict_index]\n",
    "    if (predict_det > thresh):\n",
    "        # get the first result\n",
    "        label_class_name = get_key(class_label_dict, label)[0]\n",
    "        test_class_name = get_key(class_label_dict, np.argmax(all_test_results[i]))[0]\n",
    "#     print(label_class_name)\n",
    "#     print(total_predictions_dict[label_class_name].keys())\n",
    "        total_predictions_dict[label_class_name][test_class_name] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MC': 0, 'SCC_G': 0, 'ASCUS': 0, 'SCC_R': 0, 'LSIL_F': 0, 'AGC_B': 0, 'LSIL_E': 0, 'HSIL_M': 0, 'FUNGI': 0, 'RC': 444, 'VIRUS': 0, 'TRI': 0, 'AGC_A': 0, 'EC': 0, 'HSIL_S': 0, 'ACTINO': 0, 'GEC': 19, 'HSIL_B': 0, 'CC': 0, 'SC': 0}\n"
     ]
    }
   ],
   "source": [
    "print(total_predictions_dict['RC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9583\n",
      "9583\n",
      "['MC', 9571, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, '9583', 0.9987]\n",
      "3454\n",
      "3454\n",
      "['SCC_G', 0, 3270, 0, 8, 2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 167, 0, 2, 0, 2, 0, '3454', 0.9467]\n",
      "6278\n",
      "6278\n",
      "['ASCUS', 7, 1, 6197, 0, 59, 0, 6, 0, 7, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, '6278', 0.9871]\n",
      "5483\n",
      "5483\n",
      "['SCC_R', 0, 6, 0, 5472, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, '5483', 0.998]\n",
      "1657\n",
      "1657\n",
      "['LSIL_F', 0, 0, 104, 0, 1551, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '1657', 0.936]\n",
      "1483\n",
      "1483\n",
      "['AGC_B', 0, 0, 0, 0, 0, 1441, 0, 10, 11, 0, 4, 0, 0, 0, 0, 0, 2, 8, 7, 0, '1483', 0.9717]\n",
      "3921\n",
      "3921\n",
      "['LSIL_E', 3, 0, 41, 0, 2, 0, 3871, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, '3921', 0.9872]\n",
      "743\n",
      "743\n",
      "['EC', 0, 0, 0, 0, 0, 2, 0, 728, 12, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, '743', 0.9798]\n",
      "6365\n",
      "6365\n",
      "['HSIL_M', 0, 3, 0, 0, 2, 17, 0, 0, 6315, 0, 0, 0, 0, 0, 19, 0, 3, 6, 0, 0, '6365', 0.9921]\n",
      "5806\n",
      "5806\n",
      "['FUNGI', 0, 2, 0, 0, 0, 0, 0, 0, 0, 5804, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '5806', 0.9997]\n",
      "463\n",
      "463\n",
      "['RC', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 444, 0, 0, 0, 0, 0, 19, 0, 0, 0, '463', 0.959]\n",
      "3150\n",
      "3150\n",
      "['VIRUS', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3068, 0, 0, 62, 0, 0, 0, 0, 20, '3150', 0.974]\n",
      "33669\n",
      "33669\n",
      "['TRI', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 33669, 0, 0, 0, 0, 0, 0, 0, '33669', 1.0]\n",
      "16497\n",
      "16497\n",
      "['CC', 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16482, 0, 0, 0, 0, 0, 0, '16497', 0.9991]\n",
      "20611\n",
      "20611\n",
      "['HSIL_S', 0, 55, 0, 12, 0, 0, 0, 0, 29, 0, 0, 10, 0, 0, 20252, 0, 0, 0, 0, 253, '20611', 0.9826]\n",
      "7208\n",
      "7208\n",
      "['ACTINO', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7208, 0, 0, 0, 0, '7208', 1.0]\n",
      "6250\n",
      "6250\n",
      "['GEC', 0, 0, 12, 0, 0, 1, 0, 4, 13, 0, 2, 2, 0, 0, 2, 0, 6197, 14, 2, 1, '6250', 0.9915]\n",
      "3953\n",
      "3953\n",
      "['HSIL_B', 0, 0, 0, 0, 0, 20, 0, 0, 23, 0, 4, 0, 0, 0, 0, 0, 2, 3901, 3, 0, '3953', 0.9868]\n",
      "3053\n",
      "3053\n",
      "['AGC_A', 0, 2, 0, 0, 0, 4, 0, 0, 28, 0, 0, 0, 0, 0, 0, 0, 10, 6, 3003, 0, '3053', 0.9836]\n",
      "5427\n",
      "5427\n",
      "['SC', 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 573, 0, 0, 0, 0, 4852, '5427', 0.894]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "out = open('confusion_matrix.csv','a', newline='')\n",
    "csv_write = csv.writer(out,dialect='excel')\n",
    "\n",
    "# write the title\n",
    "line = [class_name for class_name, label in class_label_dict.items()]\n",
    "line = [\" \"] + line + [\"TOTAL\"] + [\"ACC\"]\n",
    "csv_write.writerow(line)\n",
    "\n",
    "# write rows\n",
    "\n",
    "true_num = 0\n",
    "all_num = 0\n",
    "\n",
    "for row_class_name, label in class_label_dict.items():\n",
    "    one_class_total_predict = 0\n",
    "    line = [row_class_name]\n",
    "    for column_class_name, label in class_label_dict.items():\n",
    "        one_class_total_predict += total_predictions_dict[row_class_name][column_class_name]\n",
    "    \n",
    "    for column_class_name, label in class_label_dict.items():\n",
    "        one_class_cur_predict = total_predictions_dict[row_class_name][column_class_name]\n",
    "        # acc\n",
    "        #acc = round((one_class_cur_predict / one_class_total_predict), 4)\n",
    "        #line.append(str(acc))\n",
    "        # num\n",
    "        line.append(one_class_cur_predict)\n",
    "    print(one_class_total_predict)\n",
    "    print(str(one_class_total_predict))\n",
    "    line.append(str(one_class_total_predict))\n",
    "    line.append(round((total_predictions_dict[row_class_name][row_class_name] / one_class_total_predict), 4))       \n",
    "    print(line)\n",
    "    csv_write.writerow(line)\n",
    "    \n",
    "    true_num += total_predictions_dict[row_class_name][row_class_name]\n",
    "    all_num += one_class_total_predict\n",
    "    \n",
    "csv_write.writerow([\"ALL_ACC\"] + [round((true_num / all_num), 4)])\n",
    "    \n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

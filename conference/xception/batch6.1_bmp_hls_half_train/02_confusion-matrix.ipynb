{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import * \n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from multiprocessing import cpu_count\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 20\n",
    "nb_cpus = cpu_count()//2\n",
    "nb_gpus = 4\n",
    "\n",
    "image_size = (299, 299)\n",
    "input_shape= (299, 299, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 20)           20902460    lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Concatenate)           (None, 20)           0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "                                                                 model_1[3][0]                    \n",
      "                                                                 model_1[4][0]                    \n",
      "==================================================================================================\n",
      "Total params: 20,902,460\n",
      "Trainable params: 20,847,932\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    input_tensor = Input(input_shape)\n",
    "    x = Lambda(xception.preprocess_input)(input_tensor)\n",
    "\n",
    "    base_model = Xception(input_tensor=x, weights=None, include_top=False)\n",
    "    m_out = base_model.output\n",
    "    p_out = GlobalAveragePooling2D()(m_out)\n",
    "    p_out = Dropout(1.0)(p_out)\n",
    "    predictions = Dense(nb_classes, activation='softmax')(p_out)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "model = multi_gpu_model(model, gpus=nb_gpus)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights_001_0.2472.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38043 images belonging to 20 classes.\n",
      "298/298 [==============================] - 150s 505ms/step\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "test_path = \"/home/cnn/Documents/batch6.1/train6/valid\"\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "test_generator = gen.flow_from_directory(test_path, \n",
    "                                         target_size=image_size, \n",
    "                                         shuffle=False,\n",
    "                                         batch_size=batch_size)\n",
    "test_img_nums = test_generator.samples\n",
    "all_test_results = model.predict_generator(test_generator, \n",
    "                                           len(test_generator), \n",
    "                                           workers=nb_cpus, \n",
    "                                           use_multiprocessing=True,\n",
    "                                           verbose=1)\n",
    "all_labels = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TRI': 18, 'RC': 14, 'GEC': 7, 'SC': 15, 'ACTINO': 0, 'HSIL_S': 10, 'AGC_A': 1, 'SCC_R': 17, 'HSIL_M': 9, 'SCC_G': 16, 'VIRUS': 19, 'CC': 4, 'ASCUS': 3, 'MC': 13, 'EC': 5, 'HSIL_B': 8, 'AGC_B': 2, 'LSIL_E': 11, 'LSIL_F': 12, 'FUNGI': 6}\n"
     ]
    }
   ],
   "source": [
    "class_label_dict = test_generator.class_indices\n",
    "print(test_generator.class_indices)\n",
    "def get_key(dict_, value):\n",
    "    return [k for k, v in dict_.items() if v == value]\n",
    "\n",
    "# create class num lens dict, every dict store current class predict num\n",
    "total_predictions_dict = {}\n",
    "for row_class_name, label in class_label_dict.items():\n",
    "    total_predictions_dict[row_class_name] = {}\n",
    "    for column_class_name, label in class_label_dict.items():\n",
    "        total_predictions_dict[row_class_name][column_class_name] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.95\n",
    "\n",
    "for i, label in enumerate(all_labels):\n",
    "    predict_index = np.argmax(all_test_results[i])\n",
    "    predict_det = all_test_results[i][predict_index]\n",
    "    if (predict_det > thresh):\n",
    "        # get the first result\n",
    "        label_class_name = get_key(class_label_dict, label)[0]\n",
    "        test_class_name = get_key(class_label_dict, np.argmax(all_test_results[i]))[0]\n",
    "#     print(label_class_name)\n",
    "#     print(total_predictions_dict[label_class_name].keys())\n",
    "        total_predictions_dict[label_class_name][test_class_name] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TRI': 0, 'SCC_R': 0, 'GEC': 9, 'SC': 0, 'ACTINO': 0, 'HSIL_S': 0, 'AGC_A': 0, 'CC': 0, 'EC': 3, 'SCC_G': 0, 'VIRUS': 0, 'RC': 436, 'ASCUS': 0, 'MC': 0, 'HSIL_M': 0, 'HSIL_B': 0, 'AGC_B': 0, 'LSIL_E': 0, 'LSIL_F': 0, 'FUNGI': 0}\n"
     ]
    }
   ],
   "source": [
    "print(total_predictions_dict['RC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33658\n",
      "33658\n",
      "['TRI', 33646, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, '33658', 0.9996]\n",
      "448\n",
      "448\n",
      "['RC', 0, 436, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, '448', 0.9732]\n",
      "5913\n",
      "5913\n",
      "['GEC', 0, 18, 5732, 2, 3, 17, 19, 0, 17, 11, 2, 0, 4, 0, 15, 31, 40, 0, 2, 0, '5913', 0.9694]\n",
      "4132\n",
      "4132\n",
      "['SC', 25, 0, 1, 3358, 0, 716, 0, 0, 1, 2, 29, 0, 0, 0, 0, 0, 0, 0, 0, 0, '4132', 0.8127]\n",
      "7189\n",
      "7189\n",
      "['ACTINO', 0, 0, 0, 0, 7130, 59, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '7189', 0.9918]\n",
      "18022\n",
      "18022\n",
      "['HSIL_S', 1, 0, 4, 320, 0, 17521, 4, 16, 13, 113, 23, 0, 7, 0, 0, 0, 0, 0, 0, 0, '18022', 0.9722]\n",
      "2949\n",
      "2949\n",
      "['AGC_A', 0, 0, 27, 0, 0, 0, 2858, 0, 7, 27, 0, 0, 0, 0, 0, 20, 6, 0, 4, 0, '2949', 0.9691]\n",
      "5407\n",
      "5407\n",
      "['SCC_R', 0, 0, 0, 1, 0, 42, 0, 5360, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, '5407', 0.9913]\n",
      "5984\n",
      "5984\n",
      "['HSIL_M', 0, 0, 6, 0, 0, 26, 20, 0, 5863, 11, 0, 0, 0, 0, 0, 34, 23, 0, 1, 0, '5984', 0.9798]\n",
      "3214\n",
      "3214\n",
      "['SCC_G', 0, 0, 24, 8, 0, 232, 5, 23, 4, 2890, 0, 0, 15, 1, 0, 0, 0, 2, 10, 0, '3214', 0.8992]\n",
      "3204\n",
      "3204\n",
      "['VIRUS', 0, 1, 8, 8, 0, 30, 0, 0, 1, 0, 3156, 0, 0, 0, 0, 0, 0, 0, 0, 0, '3204', 0.985]\n",
      "16300\n",
      "16300\n",
      "['CC', 0, 0, 0, 0, 0, 752, 0, 0, 0, 0, 0, 15517, 0, 31, 0, 0, 0, 0, 0, 0, '16300', 0.952]\n",
      "5457\n",
      "5457\n",
      "['ASCUS', 0, 0, 4, 1, 0, 83, 0, 0, 6, 6, 2, 1, 5158, 16, 0, 0, 0, 68, 110, 2, '5457', 0.9452]\n",
      "9341\n",
      "9341\n",
      "['MC', 0, 0, 0, 0, 0, 305, 0, 0, 0, 0, 0, 57, 12, 8951, 0, 0, 0, 4, 0, 12, '9341', 0.9582]\n",
      "675\n",
      "675\n",
      "['EC', 0, 0, 29, 0, 0, 0, 3, 0, 1, 0, 0, 1, 0, 0, 627, 1, 13, 0, 0, 0, '675', 0.9289]\n",
      "3575\n",
      "3575\n",
      "['HSIL_B', 0, 9, 15, 0, 0, 4, 37, 0, 43, 0, 0, 0, 0, 0, 2, 3451, 14, 0, 0, 0, '3575', 0.9653]\n",
      "1266\n",
      "1266\n",
      "['AGC_B', 0, 9, 22, 0, 0, 0, 17, 0, 14, 0, 0, 0, 0, 0, 16, 15, 1173, 0, 0, 0, '1266', 0.9265]\n",
      "3808\n",
      "3808\n",
      "['LSIL_E', 0, 0, 0, 0, 0, 37, 0, 0, 0, 0, 0, 0, 35, 1, 0, 0, 0, 3724, 9, 2, '3808', 0.9779]\n",
      "1288\n",
      "1288\n",
      "['LSIL_F', 0, 0, 1, 0, 0, 62, 0, 0, 1, 4, 0, 0, 176, 0, 0, 0, 0, 2, 1042, 0, '1288', 0.809]\n",
      "5748\n",
      "5748\n",
      "['FUNGI', 0, 1, 0, 1, 13, 17, 0, 9, 0, 1, 0, 0, 0, 15, 0, 0, 0, 1, 1, 5689, '5748', 0.9897]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "out = open('confusion_matrix.csv','a', newline='')\n",
    "csv_write = csv.writer(out,dialect='excel')\n",
    "\n",
    "# write the title\n",
    "line = [class_name for class_name, label in class_label_dict.items()]\n",
    "line = [\" \"] + line + [\"TOTAL\"] + [\"ACC\"]\n",
    "csv_write.writerow(line)\n",
    "\n",
    "# write rows\n",
    "\n",
    "true_num = 0\n",
    "all_num = 0\n",
    "\n",
    "for row_class_name, label in class_label_dict.items():\n",
    "    one_class_total_predict = 0\n",
    "    line = [row_class_name]\n",
    "    for column_class_name, label in class_label_dict.items():\n",
    "        one_class_total_predict += total_predictions_dict[row_class_name][column_class_name]\n",
    "    \n",
    "    for column_class_name, label in class_label_dict.items():\n",
    "        one_class_cur_predict = total_predictions_dict[row_class_name][column_class_name]\n",
    "        # acc\n",
    "        #acc = round((one_class_cur_predict / one_class_total_predict), 4)\n",
    "        #line.append(str(acc))\n",
    "        # num\n",
    "        line.append(one_class_cur_predict)\n",
    "    print(one_class_total_predict)\n",
    "    print(str(one_class_total_predict))\n",
    "    line.append(str(one_class_total_predict))\n",
    "    line.append(round((total_predictions_dict[row_class_name][row_class_name] / one_class_total_predict), 4))       \n",
    "    print(line)\n",
    "    csv_write.writerow(line)\n",
    "    \n",
    "    true_num += total_predictions_dict[row_class_name][row_class_name]\n",
    "    all_num += one_class_total_predict\n",
    "    \n",
    "csv_write.writerow([\"ALL_ACC\"] + [round((true_num / all_num), 4)])\n",
    "    \n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

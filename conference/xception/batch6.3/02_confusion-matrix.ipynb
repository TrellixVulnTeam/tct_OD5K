{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.models import * \n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from multiprocessing import cpu_count\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 21\n",
    "nb_cpus = cpu_count()//2\n",
    "nb_gpus = 4\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0,1,2,3'\n",
    "\n",
    "image_size = (299, 299)\n",
    "input_shape= (299, 299, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 21)           20904509    lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Concatenate)           (None, 21)           0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "                                                                 model_1[3][0]                    \n",
      "                                                                 model_1[4][0]                    \n",
      "==================================================================================================\n",
      "Total params: 20,904,509\n",
      "Trainable params: 20,849,981\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    input_tensor = Input(input_shape)\n",
    "    x = Lambda(xception.preprocess_input)(input_tensor)\n",
    "\n",
    "    base_model = Xception(input_tensor=x, weights=None, include_top=False)\n",
    "    m_out = base_model.output\n",
    "    p_out = GlobalAveragePooling2D()(m_out)\n",
    "    p_out = Dropout(1.0)(p_out)\n",
    "    predictions = Dense(nb_classes, activation='softmax')(p_out)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "model = multi_gpu_model(model, gpus=nb_gpus)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('batch6.3_008_0.0763.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 49086 images belonging to 21 classes.\n",
      "767/767 [==============================] - 186s 242ms/step\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "test_path = \"/home/ssd0/Develop/liyu/xcp-batch6.3/CELLS-new-half299/valid\"\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "test_generator = gen.flow_from_directory(test_path, \n",
    "                                         target_size=image_size, \n",
    "                                         shuffle=False,\n",
    "                                         batch_size=batch_size)\n",
    "test_img_nums = test_generator.samples\n",
    "all_test_results = model.predict_generator(test_generator, \n",
    "                                           len(test_generator), \n",
    "                                           workers=nb_cpus, \n",
    "                                           use_multiprocessing=True,\n",
    "                                           verbose=1)\n",
    "all_labels = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SCC_G': 17, 'ACTINO': 0, 'HSIL_B': 8, 'LSIL_E': 11, 'CC': 4, 'FUNGI': 6, 'HSIL_S': 10, 'TRI': 19, 'LSIL_F': 12, 'AGC_A': 1, 'EC': 5, 'VIRUS': 20, 'SC': 16, 'MC': 13, 'ASCUS': 3, 'HSIL_M': 9, 'PH': 14, 'AGC_B': 2, 'RC': 15, 'SCC_R': 18, 'GEC': 7}\n"
     ]
    }
   ],
   "source": [
    "class_label_dict = test_generator.class_indices\n",
    "print(test_generator.class_indices)\n",
    "def get_key(dict_, value):\n",
    "    return [k for k, v in dict_.items() if v == value]\n",
    "\n",
    "# create class num lens dict, every dict store current class predict num\n",
    "total_predictions_dict = {}\n",
    "for row_class_name, label in class_label_dict.items():\n",
    "    total_predictions_dict[row_class_name] = {}\n",
    "    for column_class_name, label in class_label_dict.items():\n",
    "        total_predictions_dict[row_class_name][column_class_name] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh = 0.95\n",
    "\n",
    "for i, label in enumerate(all_labels):\n",
    "    predict_index = np.argmax(all_test_results[i])\n",
    "    predict_det = all_test_results[i][predict_index]\n",
    "    if (predict_det > thresh):\n",
    "        # get the first result\n",
    "        label_class_name = get_key(class_label_dict, label)[0]\n",
    "        test_class_name = get_key(class_label_dict, np.argmax(all_test_results[i]))[0]\n",
    "#     print(label_class_name)\n",
    "#     print(total_predictions_dict[label_class_name].keys())\n",
    "        total_predictions_dict[label_class_name][test_class_name] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SCC_G': 0, 'ACTINO': 0, 'HSIL_B': 0, 'SCC_R': 0, 'CC': 0, 'FUNGI': 0, 'ASCUS': 0, 'HSIL_S': 0, 'LSIL_F': 0, 'AGC_A': 0, 'EC': 0, 'VIRUS': 0, 'SC': 0, 'TRI': 0, 'LSIL_E': 0, 'MC': 0, 'AGC_B': 0, 'GEC': 34, 'PH': 0, 'RC': 3378, 'HSIL_M': 1}\n"
     ]
    }
   ],
   "source": [
    "print(total_predictions_dict['RC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3531\n",
      "3531\n",
      "['SCC_G', 3393, 0, 0, 0, 0, 0, 119, 0, 0, 12, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 6, '3531', 0.9609]\n",
      "11266\n",
      "11266\n",
      "['ACTINO', 0, 11266, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '11266', 1.0]\n",
      "3733\n",
      "3733\n",
      "['HSIL_B', 0, 0, 3637, 0, 0, 0, 0, 0, 0, 0, 13, 0, 0, 0, 0, 41, 0, 30, 12, 0, 0, '3733', 0.9743]\n",
      "5028\n",
      "5028\n",
      "['LSIL_E', 0, 0, 0, 4967, 0, 0, 0, 0, 25, 0, 0, 0, 0, 12, 16, 0, 8, 0, 0, 0, 0, '5028', 0.9879]\n",
      "15414\n",
      "15414\n",
      "['CC', 0, 0, 0, 0, 15407, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, '15414', 0.9995]\n",
      "9089\n",
      "9089\n",
      "['FUNGI', 0, 0, 0, 0, 0, 9084, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, '9089', 0.9994]\n",
      "32361\n",
      "32361\n",
      "['HSIL_S', 153, 0, 0, 0, 0, 0, 31814, 0, 0, 0, 0, 9, 353, 0, 2, 28, 0, 0, 0, 2, 0, '32361', 0.9831]\n",
      "33631\n",
      "33631\n",
      "['TRI', 0, 0, 0, 0, 0, 0, 0, 33613, 0, 0, 0, 0, 18, 0, 0, 0, 0, 0, 0, 0, 0, '33631', 0.9995]\n",
      "2729\n",
      "2729\n",
      "['LSIL_F', 0, 0, 0, 24, 0, 0, 0, 0, 2498, 0, 0, 0, 0, 0, 195, 0, 0, 0, 12, 0, 0, '2729', 0.9154]\n",
      "3049\n",
      "3049\n",
      "['AGC_A', 0, 0, 0, 0, 0, 0, 0, 0, 0, 3033, 0, 0, 0, 0, 0, 3, 0, 8, 0, 0, 5, '3049', 0.9948]\n",
      "1418\n",
      "1418\n",
      "['EC', 0, 0, 3, 0, 0, 0, 0, 0, 8, 0, 1334, 0, 0, 0, 0, 20, 0, 26, 1, 0, 26, '1418', 0.9408]\n",
      "5521\n",
      "5521\n",
      "['VIRUS', 0, 0, 0, 0, 0, 0, 29, 0, 0, 0, 0, 5483, 9, 0, 0, 0, 0, 0, 0, 0, 0, '5521', 0.9931]\n",
      "10359\n",
      "10359\n",
      "['SC', 14, 0, 0, 0, 0, 0, 616, 0, 0, 0, 0, 4, 9722, 0, 0, 0, 0, 0, 0, 0, 3, '10359', 0.9385]\n",
      "8042\n",
      "8042\n",
      "['MC', 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 7999, 0, 0, 41, 0, 0, 0, 0, '8042', 0.9947]\n",
      "4835\n",
      "4835\n",
      "['ASCUS', 0, 0, 0, 29, 0, 0, 2, 0, 145, 0, 0, 0, 0, 0, 4656, 0, 3, 0, 0, 0, 0, '4835', 0.963]\n",
      "6125\n",
      "6125\n",
      "['HSIL_M', 4, 0, 26, 0, 0, 0, 12, 0, 0, 0, 5, 0, 0, 0, 0, 6070, 0, 5, 0, 0, 3, '6125', 0.991]\n",
      "7341\n",
      "7341\n",
      "['PH', 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 66, 13, 0, 7257, 0, 0, 0, 0, '7341', 0.9886]\n",
      "1428\n",
      "1428\n",
      "['AGC_B', 0, 0, 2, 0, 0, 0, 0, 0, 0, 4, 74, 0, 0, 0, 0, 0, 0, 1348, 0, 0, 0, '1428', 0.944]\n",
      "3413\n",
      "3413\n",
      "['RC', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3378, 0, 34, '3413', 0.9897]\n",
      "5543\n",
      "5543\n",
      "['SCC_R', 7, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5529, 3, '5543', 0.9975]\n",
      "11667\n",
      "11667\n",
      "['GEC', 2, 0, 2, 0, 0, 0, 0, 0, 2, 6, 20, 0, 0, 0, 8, 3, 0, 0, 53, 0, 11571, '11667', 0.9918]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "out = open('confusion_matrix_95.csv','a', newline='')\n",
    "csv_write = csv.writer(out,dialect='excel')\n",
    "\n",
    "# write the title\n",
    "line = [class_name for class_name, label in class_label_dict.items()]\n",
    "line = [\" \"] + line + [\"TOTAL\"] + [\"ACC\"]\n",
    "csv_write.writerow(line)\n",
    "\n",
    "# write rows\n",
    "\n",
    "true_num = 0\n",
    "all_num = 0\n",
    "\n",
    "for row_class_name, label in class_label_dict.items():\n",
    "    one_class_total_predict = 0\n",
    "    line = [row_class_name]\n",
    "    for column_class_name, label in class_label_dict.items():\n",
    "        one_class_total_predict += total_predictions_dict[row_class_name][column_class_name]\n",
    "    \n",
    "    for column_class_name, label in class_label_dict.items():\n",
    "        one_class_cur_predict = total_predictions_dict[row_class_name][column_class_name]\n",
    "        # acc\n",
    "        #acc = round((one_class_cur_predict / one_class_total_predict), 4)\n",
    "        #line.append(str(acc))\n",
    "        # num\n",
    "        line.append(one_class_cur_predict)\n",
    "    print(one_class_total_predict)\n",
    "    print(str(one_class_total_predict))\n",
    "    line.append(str(one_class_total_predict))\n",
    "    line.append(round((total_predictions_dict[row_class_name][row_class_name] / one_class_total_predict), 4))       \n",
    "    print(line)\n",
    "    csv_write.writerow(line)\n",
    "    \n",
    "    true_num += total_predictions_dict[row_class_name][row_class_name]\n",
    "    all_num += one_class_total_predict\n",
    "    \n",
    "csv_write.writerow([\"ALL_ACC\"] + [round((true_num / all_num), 4)])\n",
    "    \n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new training data\n",
    "1. make half-sized, 299-aligned images\n",
    "2. split data\n",
    "3. augment train\n",
    "\n",
    "## training data addon\n",
    "1. generate raw addon data: from original cell images (various sizes), to half-sized, 299-aligned images\n",
    "2. split raw addon data to train/valid\n",
    "3. augment train\n",
    "4. add new addon data to training data pool, change image file name before merging, if neccessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from multiprocessing import cpu_count\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HLS_L = [0.7]\n",
    "HLS_S = [0.4, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scan_files(directory, prefix=None, postfix=None):\n",
    "    files_list = []\n",
    "    for root, sub_dirs, files in os.walk(directory):\n",
    "        for special_file in files:\n",
    "            if postfix:\n",
    "                if special_file.endswith(postfix):\n",
    "                    files_list.append(os.path.join(root, special_file))\n",
    "            elif prefix:\n",
    "                if special_file.startswith(prefix):\n",
    "                    files_list.append(os.path.join(root, special_file))\n",
    "            else:\n",
    "                files_list.append(os.path.join(root, special_file))\n",
    "    return files_list\n",
    "\n",
    "def hls_trans_smart(image, HLS_L=HLS_L, HLS_S=HLS_S):\n",
    "    # image = cv2.imread(image_name)\n",
    "    # image = np.asarray(image)\n",
    "\n",
    "    # 图像归一化，且转换为浮点型\n",
    "    hlsImg = image.astype(np.float32)\n",
    "    hlsImg = hlsImg / 255.0\n",
    "    # 颜色空间转换 BGR转为HLS\n",
    "    hlsImg = cv2.cvtColor(hlsImg, cv2.COLOR_BGR2HLS)\n",
    "    \n",
    "    # 1.调整亮度\n",
    "    l = np.average(hlsImg[:,:,1])\n",
    "    i = len(HLS_L) - 1\n",
    "    while i != -1 and HLS_L[i] > l:\n",
    "        i -= 1\n",
    "    if i != len(HLS_L)-1:\n",
    "        hls_l = HLS_L[i+1]\n",
    "        hlsImg[:, :, 1] = hls_l / l * hlsImg[:, :, 1]\n",
    "        hlsImg[:, :, 1][hlsImg[:, :, 1] > 1] = 1\n",
    "        # print(image_name, \"changing l\", l, \"to\", hls_l)\n",
    "        \n",
    "    # 2.调整饱和度\n",
    "    s = np.average(hlsImg[:,:,2])\n",
    "    i = len(HLS_S) - 1\n",
    "    while i != -1 and HLS_S[i] > s:\n",
    "        i -= 1\n",
    "    if i != len(HLS_S)-1:\n",
    "        hls_s = HLS_S[i+1]\n",
    "        hlsImg[:, :, 2] = hls_s / s * hlsImg[:, :, 2]\n",
    "        hlsImg[:, :, 2][hlsImg[:, :, 2] > 1] = 1\n",
    "        # print(image_name, \"changing s\", s, \"to\", hls_s)\n",
    "        \n",
    "    # HLS2BGR\n",
    "    hlsImg = cv2.cvtColor(hlsImg, cv2.COLOR_HLS2BGR)\n",
    "    # 转换为8位unsigned char\n",
    "    hlsImg = hlsImg * 255\n",
    "    image = hlsImg.astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# half the image size\n",
    "def half_image(image_name, save_dir, depth):\n",
    "    tokens = image_name.rsplit(os.sep, depth+1)\n",
    "    image_name_ = os.path.join(save_dir, *tokens[1:])\n",
    "#     os.makedirs(os.path.dirname(image_name_), exist_ok=True)\n",
    "    with Image.open(image_name) as image:\n",
    "        w, h = image.size\n",
    "        image.resize((w//2, h//2)).save(image_name_)\n",
    "\n",
    "# half the image size and pad/crop to size 299\n",
    "def half_and_pad_image(image_name, save_dir, depth, size, hls):\n",
    "    tokens = image_name.rsplit(os.sep, depth+1)\n",
    "    image_name_ = os.path.join(save_dir, *tokens[1:])\n",
    "    os.makedirs(os.path.dirname(image_name_), exist_ok=True)\n",
    "    \n",
    "#     with Image.open(image_name) as image:\n",
    "#         w, h = image.size\n",
    "#         img = image.resize((w//2, h//2))\n",
    "#         img_croped = img.crop(\n",
    "#             (\n",
    "#                 -((size - img.size[0]) // 2),\n",
    "#                 -((size - img.size[1]) // 2),\n",
    "#                 size - ((size - img.size[0]) // 2),\n",
    "#                 size - ((size - img.size[1]) // 2)\n",
    "#             )\n",
    "#         )\n",
    "#         img_croped.save(image_name_, quality=100)\n",
    "        \n",
    "    image = cv2.imread(image_name)\n",
    "    \n",
    "    # half-size image\n",
    "#     h, w, _ = image.shape\n",
    "#     image = cv2.resize(image, (w//2, h//2))\n",
    "    image = cv2.pyrDown(image)\n",
    "    \n",
    "    # change l and s of image\n",
    "    if hls:\n",
    "        image = hls_trans_smart(image)\n",
    "\n",
    "#     new_image = np.ones((size, size, 3)) * 255  # white\n",
    "    new_image = np.zeros((size, size, 3))  # black\n",
    "    h, w, _ = image.shape\n",
    "    if h < size and w < size:\n",
    "        new_image[(size-h)//2:h+(size-h)//2, (size-w)//2:w+(size-w)//2, :] = image\n",
    "    elif h < size:\n",
    "        new_image[(size-h)//2:h+(size-h)//2, :, :] = image[:, (w-size)//2:size+(w-size)//2, :]\n",
    "    elif w < size:\n",
    "        new_image[:, (size-w)//2:w+(size-w)//2, :] = image[(h-size)//2:size+(h-size)//2, :, :]\n",
    "    else:\n",
    "        new_image[:, :, :] = image[(h-size)//2:size+(h-size)//2, (w-size)//2:size+(w-size)//2, :]\n",
    "#     cv2.imwrite(image_name_, new_image, [int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
    "    cv2.imwrite(image_name_, new_image)\n",
    "        \n",
    "\n",
    "def batch_half_image(image_names, save_dir, depth, size, hls):\n",
    "    for image_name in image_names:\n",
    "#         half_image(image_name, save_dir, depth)\n",
    "        half_and_pad_image(image_name, save_dir, depth, size, hls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(cells_dir, cells_dir_half, depth=1, size=299, hls=True):\n",
    "    image_names = scan_files(cells_dir, postfix=\".bmp\")\n",
    "    print(\"# images\", len(image_names))\n",
    "    \n",
    "    executor = ProcessPoolExecutor(max_workers=cpu_count())\n",
    "    tasks = []\n",
    "    \n",
    "    batch_size = 1000\n",
    "    for i in range(0, len(image_names), batch_size):\n",
    "        batch = image_names[i : i+batch_size]\n",
    "        tasks.append(executor.submit(batch_half_image, batch, cells_dir_half, depth, size, hls))\n",
    "\n",
    "    job_count = len(tasks)\n",
    "    for future in as_completed(tasks):\n",
    "        # result = future.result()  # get the returning result from calling fuction\n",
    "        job_count -= 1\n",
    "        print(\"One Job Done, Remaining Job Count: %s\" % (job_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# images 148300\n",
      "One Job Done, Remaining Job Count: 148\n",
      "One Job Done, Remaining Job Count: 147\n",
      "One Job Done, Remaining Job Count: 146\n",
      "One Job Done, Remaining Job Count: 145\n",
      "One Job Done, Remaining Job Count: 144\n",
      "One Job Done, Remaining Job Count: 143\n",
      "One Job Done, Remaining Job Count: 142\n",
      "One Job Done, Remaining Job Count: 141\n",
      "One Job Done, Remaining Job Count: 140\n",
      "One Job Done, Remaining Job Count: 139\n",
      "One Job Done, Remaining Job Count: 138\n",
      "One Job Done, Remaining Job Count: 137\n",
      "One Job Done, Remaining Job Count: 136\n",
      "One Job Done, Remaining Job Count: 135\n",
      "One Job Done, Remaining Job Count: 134\n",
      "One Job Done, Remaining Job Count: 133\n",
      "One Job Done, Remaining Job Count: 132\n",
      "One Job Done, Remaining Job Count: 131\n",
      "One Job Done, Remaining Job Count: 130\n",
      "One Job Done, Remaining Job Count: 129\n",
      "One Job Done, Remaining Job Count: 128\n",
      "One Job Done, Remaining Job Count: 127\n",
      "One Job Done, Remaining Job Count: 126\n",
      "One Job Done, Remaining Job Count: 125\n",
      "One Job Done, Remaining Job Count: 124\n",
      "One Job Done, Remaining Job Count: 123\n",
      "One Job Done, Remaining Job Count: 122\n",
      "One Job Done, Remaining Job Count: 121\n",
      "One Job Done, Remaining Job Count: 120\n",
      "One Job Done, Remaining Job Count: 119\n",
      "One Job Done, Remaining Job Count: 118\n",
      "One Job Done, Remaining Job Count: 117\n",
      "One Job Done, Remaining Job Count: 116\n",
      "One Job Done, Remaining Job Count: 115\n",
      "One Job Done, Remaining Job Count: 114\n",
      "One Job Done, Remaining Job Count: 113\n",
      "One Job Done, Remaining Job Count: 112\n",
      "One Job Done, Remaining Job Count: 111\n",
      "One Job Done, Remaining Job Count: 110\n",
      "One Job Done, Remaining Job Count: 109\n",
      "One Job Done, Remaining Job Count: 108\n",
      "One Job Done, Remaining Job Count: 107\n",
      "One Job Done, Remaining Job Count: 106\n",
      "One Job Done, Remaining Job Count: 105\n",
      "One Job Done, Remaining Job Count: 104\n",
      "One Job Done, Remaining Job Count: 103\n",
      "One Job Done, Remaining Job Count: 102\n",
      "One Job Done, Remaining Job Count: 101\n",
      "One Job Done, Remaining Job Count: 100\n",
      "One Job Done, Remaining Job Count: 99\n",
      "One Job Done, Remaining Job Count: 98\n",
      "One Job Done, Remaining Job Count: 97\n",
      "One Job Done, Remaining Job Count: 96\n",
      "One Job Done, Remaining Job Count: 95\n",
      "One Job Done, Remaining Job Count: 94\n",
      "One Job Done, Remaining Job Count: 93\n",
      "One Job Done, Remaining Job Count: 92\n",
      "One Job Done, Remaining Job Count: 91\n",
      "One Job Done, Remaining Job Count: 90\n",
      "One Job Done, Remaining Job Count: 89\n",
      "One Job Done, Remaining Job Count: 88\n",
      "One Job Done, Remaining Job Count: 87\n",
      "One Job Done, Remaining Job Count: 86\n",
      "One Job Done, Remaining Job Count: 85\n",
      "One Job Done, Remaining Job Count: 84\n",
      "One Job Done, Remaining Job Count: 83\n",
      "One Job Done, Remaining Job Count: 82\n",
      "One Job Done, Remaining Job Count: 81\n",
      "One Job Done, Remaining Job Count: 80\n",
      "One Job Done, Remaining Job Count: 79\n",
      "One Job Done, Remaining Job Count: 78\n",
      "One Job Done, Remaining Job Count: 77\n",
      "One Job Done, Remaining Job Count: 76\n",
      "One Job Done, Remaining Job Count: 75\n",
      "One Job Done, Remaining Job Count: 74\n",
      "One Job Done, Remaining Job Count: 73\n",
      "One Job Done, Remaining Job Count: 72\n",
      "One Job Done, Remaining Job Count: 71\n",
      "One Job Done, Remaining Job Count: 70\n",
      "One Job Done, Remaining Job Count: 69\n",
      "One Job Done, Remaining Job Count: 68\n",
      "One Job Done, Remaining Job Count: 67\n",
      "One Job Done, Remaining Job Count: 66\n",
      "One Job Done, Remaining Job Count: 65\n",
      "One Job Done, Remaining Job Count: 64\n",
      "One Job Done, Remaining Job Count: 63\n",
      "One Job Done, Remaining Job Count: 62\n",
      "One Job Done, Remaining Job Count: 61\n",
      "One Job Done, Remaining Job Count: 60\n",
      "One Job Done, Remaining Job Count: 59\n",
      "One Job Done, Remaining Job Count: 58\n",
      "One Job Done, Remaining Job Count: 57\n",
      "One Job Done, Remaining Job Count: 56\n",
      "One Job Done, Remaining Job Count: 55\n",
      "One Job Done, Remaining Job Count: 54\n",
      "One Job Done, Remaining Job Count: 53\n",
      "One Job Done, Remaining Job Count: 52\n",
      "One Job Done, Remaining Job Count: 51\n",
      "One Job Done, Remaining Job Count: 50\n",
      "One Job Done, Remaining Job Count: 49\n",
      "One Job Done, Remaining Job Count: 48\n",
      "One Job Done, Remaining Job Count: 47\n",
      "One Job Done, Remaining Job Count: 46\n",
      "One Job Done, Remaining Job Count: 45\n",
      "One Job Done, Remaining Job Count: 44\n",
      "One Job Done, Remaining Job Count: 43\n",
      "One Job Done, Remaining Job Count: 42\n",
      "One Job Done, Remaining Job Count: 41\n",
      "One Job Done, Remaining Job Count: 40\n",
      "One Job Done, Remaining Job Count: 39\n",
      "One Job Done, Remaining Job Count: 38\n",
      "One Job Done, Remaining Job Count: 37\n",
      "One Job Done, Remaining Job Count: 36\n",
      "One Job Done, Remaining Job Count: 35\n",
      "One Job Done, Remaining Job Count: 34\n",
      "One Job Done, Remaining Job Count: 33\n",
      "One Job Done, Remaining Job Count: 32\n",
      "One Job Done, Remaining Job Count: 31\n",
      "One Job Done, Remaining Job Count: 30\n",
      "One Job Done, Remaining Job Count: 29\n",
      "One Job Done, Remaining Job Count: 28\n",
      "One Job Done, Remaining Job Count: 27\n",
      "One Job Done, Remaining Job Count: 26\n",
      "One Job Done, Remaining Job Count: 25\n",
      "One Job Done, Remaining Job Count: 24\n",
      "One Job Done, Remaining Job Count: 23\n",
      "One Job Done, Remaining Job Count: 22\n",
      "One Job Done, Remaining Job Count: 21\n",
      "One Job Done, Remaining Job Count: 20\n",
      "One Job Done, Remaining Job Count: 19\n",
      "One Job Done, Remaining Job Count: 18\n",
      "One Job Done, Remaining Job Count: 17\n",
      "One Job Done, Remaining Job Count: 16\n",
      "One Job Done, Remaining Job Count: 15\n",
      "One Job Done, Remaining Job Count: 14\n",
      "One Job Done, Remaining Job Count: 13\n",
      "One Job Done, Remaining Job Count: 12\n",
      "One Job Done, Remaining Job Count: 11\n",
      "One Job Done, Remaining Job Count: 10\n",
      "One Job Done, Remaining Job Count: 9\n",
      "One Job Done, Remaining Job Count: 8\n",
      "One Job Done, Remaining Job Count: 7\n",
      "One Job Done, Remaining Job Count: 6\n",
      "One Job Done, Remaining Job Count: 5\n",
      "One Job Done, Remaining Job Count: 4\n",
      "One Job Done, Remaining Job Count: 3\n",
      "One Job Done, Remaining Job Count: 2\n",
      "One Job Done, Remaining Job Count: 1\n",
      "One Job Done, Remaining Job Count: 0\n"
     ]
    }
   ],
   "source": [
    "cells_dir = \"/home/hdd_array0/batch6.2_xcp/batch6.2-cells\"\n",
    "cells_dir_half299 = \"/home/hdd_array0/batch6.2_xcp/batch6.2-cells-half299-hls07\"\n",
    "for sub_dir in os.listdir(cells_dir):\n",
    "    os.makedirs(os.path.join(cells_dir_half299, sub_dir), exist_ok=True)\n",
    "\n",
    "process(cells_dir, cells_dir_half299)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data to train/valid, randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_train_and_valid(data_path, save_path, split=0.1):\n",
    "    def create_directory(save_path, subdirs):\n",
    "        for datadir in [\"train\", \"valid\"]:\n",
    "            for subdir in subdirs:\n",
    "                os.makedirs(os.path.join(save_path, datadir, subdir), exist_ok=True)\n",
    "    \n",
    "    def remove_directory(data_path, subdirs):\n",
    "        for subdir in subdirs:\n",
    "            shutil.rmtree(os.path.join(data_path, subdir))\n",
    "    \n",
    "    subdirs = os.listdir(data_path)\n",
    "    create_directory(save_path, subdirs)\n",
    "    \n",
    "    for subdir in subdirs:\n",
    "        sub_path = os.path.join(data_path, subdir)\n",
    "        sub_files = [os.path.join(sub_path, f) for f in os.listdir(sub_path) if f.endswith(\".bmp\")]\n",
    "        random.shuffle(sub_files)\n",
    "        random.shuffle(sub_files)\n",
    "        random.shuffle(sub_files)\n",
    "        \n",
    "        sub_train_path = os.path.join(save_path, \"train\", subdir)      \n",
    "        sub_train_files = sub_files[int(len(sub_files)*split):]\n",
    "        for file in sub_train_files:\n",
    "            shutil.move(file, sub_train_path)\n",
    "            \n",
    "        sub_valid_path = os.path.join(save_path, \"valid\", subdir)\n",
    "        sub_valid_files = sub_files[:int(len(sub_files)*split)]\n",
    "        for file in sub_valid_files:\n",
    "            shutil.move(file, sub_valid_path)\n",
    "            \n",
    "        print(\"{}: split # {} files to train, # {} files to valid\".format(subdir, len(sub_train_files), len(sub_valid_files)))\n",
    "        \n",
    "    remove_directory(data_path, subdirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASCUS: split # 5273 files to train, # 585 files to valid\n",
      "VIRUS: split # 4255 files to train, # 472 files to valid\n",
      "SCC_R: split # 4228 files to train, # 469 files to valid\n",
      "LSIL_E: split # 2988 files to train, # 331 files to valid\n",
      "CC: split # 11615 files to train, # 1290 files to valid\n",
      "HSIL_M: split # 4831 files to train, # 536 files to valid\n",
      "RC: split # 905 files to train, # 100 files to valid\n",
      "HSIL_S: split # 26803 files to train, # 2978 files to valid\n",
      "PH: split # 5239 files to train, # 582 files to valid\n",
      "ACTINO: split # 8456 files to train, # 939 files to valid\n",
      "GEC: split # 4822 files to train, # 535 files to valid\n",
      "SC: split # 7133 files to train, # 792 files to valid\n",
      "LSIL_F: split # 1240 files to train, # 137 files to valid\n",
      "EC: split # 569 files to train, # 63 files to valid\n",
      "MC: split # 5608 files to train, # 623 files to valid\n",
      "AGC_B: split # 1178 files to train, # 130 files to valid\n",
      "HSIL_B: split # 3000 files to train, # 333 files to valid\n",
      "TRI: split # 25273 files to train, # 2808 files to valid\n",
      "FUNGI: split # 4761 files to train, # 528 files to valid\n",
      "AGC_A: split # 2371 files to train, # 263 files to valid\n",
      "SCC_G: split # 2933 files to train, # 325 files to valid\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/hdd_array0/batch6.2_xcp/batch6.2-cells-half299\"\n",
    "save_path = \"/home/hdd_array0/batch6.2_xcp/batch6.2-cells-half299\"\n",
    "\n",
    "split_train_and_valid(data_path, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data to train/valid, based on given split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_name(file_dir):\n",
    "    files = scan_files(file_dir, postfix=\".bmp\")\n",
    "    name_map = {os.path.splitext(os.path.basename(file))[0]:file for file in files}\n",
    "    return name_map\n",
    "\n",
    "def create_directory(save_path, subdirs):\n",
    "    for datadir in [\"train\", \"valid\"]:\n",
    "        for subdir in subdirs:\n",
    "            os.makedirs(os.path.join(save_path, datadir, subdir), exist_ok=True)\n",
    "\n",
    "def remove_directory(data_path, subdirs):\n",
    "    for subdir in subdirs:\n",
    "        shutil.rmtree(os.path.join(data_path, subdir))\n",
    "\n",
    "def get_inter_tokens(file_dir, file_path):\n",
    "    tokens_dir = os.path.abspath(file_dir).split(os.sep)\n",
    "    tokens_file = os.path.abspath(os.path.dirname(file_path)).split(os.sep)\n",
    "    return tokens_file[len(tokens_dir):]\n",
    "\n",
    "def arrange_by_template(temp_dir, file_dir):\n",
    "    subdirs = os.listdir(file_dir)\n",
    "    \n",
    "    temp_name_map = map_name(temp_dir)\n",
    "    file_name_map = map_name(file_dir)\n",
    "    \n",
    "    for basename in file_name_map:\n",
    "        if not basename in temp_name_map:\n",
    "            print(basename + \" not found in \" + temp_dir)\n",
    "            continue\n",
    "        tokens = get_inter_tokens(temp_dir, temp_name_map[basename])\n",
    "        target_dir = os.path.join(file_dir, *tokens)\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "        shutil.move(file_name_map[basename], target_dir)\n",
    "        \n",
    "    remove_directory(file_dir, subdirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "template_dir = \"/home/hdd_array0/batch6.2_xcp/batch6.2-cells-half299\"\n",
    "source_dir = \"/home/hdd_array0/batch6.2_xcp/batch6.2-cells-half299-hls07\"\n",
    "\n",
    "arrange_by_template(template_dir, source_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate(image_name):\n",
    "    basename = os.path.splitext(image_name)[0]\n",
    "    jpg = Image.open(image_name)\n",
    "    jpg.rotate(90).save(basename + \"_r90.bmp\")\n",
    "    jpg.rotate(180).save(basename + \"_r180.bmp\")\n",
    "    jpg.rotate(270).save(basename + \"_r270.bmp\")\n",
    "    jpg.close()\n",
    "    \n",
    "def batch_rotate(image_names):\n",
    "    for image_name in image_names:\n",
    "        rotate(image_name)\n",
    "        \n",
    "def process(cells_dir):\n",
    "    image_names = scan_files(cells_dir, postfix=\".bmp\")\n",
    "    print(\"# images\", len(image_names))\n",
    "    \n",
    "    executor = ProcessPoolExecutor(max_workers=cpu_count())\n",
    "    tasks = []\n",
    "    \n",
    "    batch_size = 1000\n",
    "    for i in range(0, len(image_names), batch_size):\n",
    "        batch = image_names[i : i+batch_size]\n",
    "        tasks.append(executor.submit(batch_rotate, batch))\n",
    "\n",
    "    job_count = len(tasks)\n",
    "    for future in as_completed(tasks):\n",
    "        # result = future.result()  # get the returning result from calling fuction\n",
    "        job_count -= 1\n",
    "        print(\"One Job Done, Remaining Job Count: %s\" % (job_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# images 133481\n",
      "One Job Done, Remaining Job Count: 133\n",
      "One Job Done, Remaining Job Count: 132\n",
      "One Job Done, Remaining Job Count: 131\n",
      "One Job Done, Remaining Job Count: 130\n",
      "One Job Done, Remaining Job Count: 129\n",
      "One Job Done, Remaining Job Count: 128\n",
      "One Job Done, Remaining Job Count: 127\n",
      "One Job Done, Remaining Job Count: 126\n",
      "One Job Done, Remaining Job Count: 125\n",
      "One Job Done, Remaining Job Count: 124\n",
      "One Job Done, Remaining Job Count: 123\n",
      "One Job Done, Remaining Job Count: 122\n",
      "One Job Done, Remaining Job Count: 121\n",
      "One Job Done, Remaining Job Count: 120\n",
      "One Job Done, Remaining Job Count: 119\n",
      "One Job Done, Remaining Job Count: 118\n",
      "One Job Done, Remaining Job Count: 117\n",
      "One Job Done, Remaining Job Count: 116\n",
      "One Job Done, Remaining Job Count: 115\n",
      "One Job Done, Remaining Job Count: 114\n",
      "One Job Done, Remaining Job Count: 113\n",
      "One Job Done, Remaining Job Count: 112\n",
      "One Job Done, Remaining Job Count: 111\n",
      "One Job Done, Remaining Job Count: 110\n",
      "One Job Done, Remaining Job Count: 109\n",
      "One Job Done, Remaining Job Count: 108\n",
      "One Job Done, Remaining Job Count: 107\n",
      "One Job Done, Remaining Job Count: 106\n",
      "One Job Done, Remaining Job Count: 105\n",
      "One Job Done, Remaining Job Count: 104\n",
      "One Job Done, Remaining Job Count: 103\n",
      "One Job Done, Remaining Job Count: 102\n",
      "One Job Done, Remaining Job Count: 101\n",
      "One Job Done, Remaining Job Count: 100\n",
      "One Job Done, Remaining Job Count: 99\n",
      "One Job Done, Remaining Job Count: 98\n",
      "One Job Done, Remaining Job Count: 97\n",
      "One Job Done, Remaining Job Count: 96\n",
      "One Job Done, Remaining Job Count: 95\n",
      "One Job Done, Remaining Job Count: 94\n",
      "One Job Done, Remaining Job Count: 93\n",
      "One Job Done, Remaining Job Count: 92\n",
      "One Job Done, Remaining Job Count: 91\n",
      "One Job Done, Remaining Job Count: 90\n",
      "One Job Done, Remaining Job Count: 89\n",
      "One Job Done, Remaining Job Count: 88\n",
      "One Job Done, Remaining Job Count: 87\n",
      "One Job Done, Remaining Job Count: 86\n",
      "One Job Done, Remaining Job Count: 85\n",
      "One Job Done, Remaining Job Count: 84\n",
      "One Job Done, Remaining Job Count: 83\n",
      "One Job Done, Remaining Job Count: 82\n",
      "One Job Done, Remaining Job Count: 81\n",
      "One Job Done, Remaining Job Count: 80\n",
      "One Job Done, Remaining Job Count: 79\n",
      "One Job Done, Remaining Job Count: 78\n",
      "One Job Done, Remaining Job Count: 77\n",
      "One Job Done, Remaining Job Count: 76\n",
      "One Job Done, Remaining Job Count: 75\n",
      "One Job Done, Remaining Job Count: 74\n",
      "One Job Done, Remaining Job Count: 73\n",
      "One Job Done, Remaining Job Count: 72\n",
      "One Job Done, Remaining Job Count: 71\n",
      "One Job Done, Remaining Job Count: 70\n",
      "One Job Done, Remaining Job Count: 69\n",
      "One Job Done, Remaining Job Count: 68\n",
      "One Job Done, Remaining Job Count: 67\n",
      "One Job Done, Remaining Job Count: 66\n",
      "One Job Done, Remaining Job Count: 65\n",
      "One Job Done, Remaining Job Count: 64\n",
      "One Job Done, Remaining Job Count: 63\n",
      "One Job Done, Remaining Job Count: 62\n",
      "One Job Done, Remaining Job Count: 61\n",
      "One Job Done, Remaining Job Count: 60\n",
      "One Job Done, Remaining Job Count: 59\n",
      "One Job Done, Remaining Job Count: 58\n",
      "One Job Done, Remaining Job Count: 57\n",
      "One Job Done, Remaining Job Count: 56\n",
      "One Job Done, Remaining Job Count: 55\n",
      "One Job Done, Remaining Job Count: 54\n",
      "One Job Done, Remaining Job Count: 53\n",
      "One Job Done, Remaining Job Count: 52\n",
      "One Job Done, Remaining Job Count: 51\n",
      "One Job Done, Remaining Job Count: 50\n",
      "One Job Done, Remaining Job Count: 49\n",
      "One Job Done, Remaining Job Count: 48\n",
      "One Job Done, Remaining Job Count: 47\n",
      "One Job Done, Remaining Job Count: 46\n",
      "One Job Done, Remaining Job Count: 45\n",
      "One Job Done, Remaining Job Count: 44\n",
      "One Job Done, Remaining Job Count: 43\n",
      "One Job Done, Remaining Job Count: 42\n",
      "One Job Done, Remaining Job Count: 41\n",
      "One Job Done, Remaining Job Count: 40\n",
      "One Job Done, Remaining Job Count: 39\n",
      "One Job Done, Remaining Job Count: 38\n",
      "One Job Done, Remaining Job Count: 37\n",
      "One Job Done, Remaining Job Count: 36\n",
      "One Job Done, Remaining Job Count: 35\n",
      "One Job Done, Remaining Job Count: 34\n",
      "One Job Done, Remaining Job Count: 33\n",
      "One Job Done, Remaining Job Count: 32\n",
      "One Job Done, Remaining Job Count: 31\n",
      "One Job Done, Remaining Job Count: 30\n",
      "One Job Done, Remaining Job Count: 29\n",
      "One Job Done, Remaining Job Count: 28\n",
      "One Job Done, Remaining Job Count: 27\n",
      "One Job Done, Remaining Job Count: 26\n",
      "One Job Done, Remaining Job Count: 25\n",
      "One Job Done, Remaining Job Count: 24\n",
      "One Job Done, Remaining Job Count: 23\n",
      "One Job Done, Remaining Job Count: 22\n",
      "One Job Done, Remaining Job Count: 21\n",
      "One Job Done, Remaining Job Count: 20\n",
      "One Job Done, Remaining Job Count: 19\n",
      "One Job Done, Remaining Job Count: 18\n",
      "One Job Done, Remaining Job Count: 17\n",
      "One Job Done, Remaining Job Count: 16\n",
      "One Job Done, Remaining Job Count: 15\n",
      "One Job Done, Remaining Job Count: 14\n",
      "One Job Done, Remaining Job Count: 13\n",
      "One Job Done, Remaining Job Count: 12\n",
      "One Job Done, Remaining Job Count: 11\n",
      "One Job Done, Remaining Job Count: 10\n",
      "One Job Done, Remaining Job Count: 9\n",
      "One Job Done, Remaining Job Count: 8\n",
      "One Job Done, Remaining Job Count: 7\n",
      "One Job Done, Remaining Job Count: 6\n",
      "One Job Done, Remaining Job Count: 5\n",
      "One Job Done, Remaining Job Count: 4\n",
      "One Job Done, Remaining Job Count: 3\n",
      "One Job Done, Remaining Job Count: 2\n",
      "One Job Done, Remaining Job Count: 1\n",
      "One Job Done, Remaining Job Count: 0\n"
     ]
    }
   ],
   "source": [
    "cells_dir = \"/home/hdd_array0/batch6.2_xcp/batch6.2-cells-half299-hls07/train\"\n",
    "\n",
    "process(cells_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy files, change filename if a file already exists in target directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scan_files(directory, prefix=None, postfix=None):\n",
    "    files_list = []\n",
    "    for root, sub_dirs, files in os.walk(directory):\n",
    "        for special_file in files:\n",
    "            if postfix:\n",
    "                if special_file.endswith(postfix):\n",
    "                    files_list.append(os.path.join(root, special_file))\n",
    "            elif prefix:\n",
    "                if special_file.startswith(prefix):\n",
    "                    files_list.append(os.path.join(root, special_file))\n",
    "            else:\n",
    "                files_list.append(os.path.join(root, special_file))\n",
    "    return files_list\n",
    "\n",
    "def get_inter_tokens(file_dir, file_path):\n",
    "    tokens_dir = os.path.abspath(file_dir).split(os.sep)\n",
    "    tokens_file = os.path.abspath(os.path.dirname(file_path)).split(os.sep)\n",
    "    return tokens_file[len(tokens_dir):]\n",
    "\n",
    "def copy_and_addon(src_folder, dst_folder, addon, postfix):\n",
    "    src_files = scan_files(src_folder, postfix=postfix)\n",
    "    for file in src_files:\n",
    "        tokens = get_inter_tokens(src_folder, file)\n",
    "        basename = os.path.splitext(os.path.basename(file))[0] + addon + postfix\n",
    "        shutil.copy(file, os.path.join(dst_folder, *tokens, basename))\n",
    "    \n",
    "def move_and_addon(src_folder, dst_folder, addon, postfix):\n",
    "    src_files = scan_files(src_folder, postfix=postfix)\n",
    "    for i,file in enumerate(src_files):\n",
    "        if i % 10000 == 0:\n",
    "            print(\"# files merged\", i)\n",
    "        tokens = get_inter_tokens(src_folder, file)\n",
    "        basename = os.path.splitext(os.path.basename(file))[0] + addon + postfix\n",
    "        shutil.move(file, os.path.join(dst_folder, *tokens, basename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# files merged 0\n",
      "# files merged 10000\n",
      "# files merged 20000\n",
      "# files merged 30000\n",
      "# files merged 40000\n",
      "# files merged 50000\n",
      "# files merged 60000\n",
      "# files merged 70000\n",
      "# files merged 80000\n",
      "# files merged 90000\n",
      "# files merged 100000\n",
      "# files merged 110000\n",
      "# files merged 120000\n",
      "# files merged 130000\n",
      "# files merged 140000\n",
      "# files merged 150000\n",
      "# files merged 160000\n",
      "# files merged 170000\n",
      "# files merged 180000\n",
      "# files merged 190000\n",
      "# files merged 200000\n",
      "# files merged 210000\n",
      "# files merged 220000\n",
      "# files merged 230000\n",
      "# files merged 240000\n",
      "# files merged 250000\n",
      "# files merged 260000\n",
      "# files merged 270000\n",
      "# files merged 280000\n",
      "# files merged 290000\n",
      "# files merged 300000\n",
      "# files merged 310000\n",
      "# files merged 320000\n",
      "# files merged 330000\n",
      "# files merged 340000\n",
      "# files merged 350000\n",
      "# files merged 360000\n",
      "# files merged 370000\n",
      "# files merged 380000\n",
      "# files merged 390000\n",
      "# files merged 400000\n",
      "# files merged 410000\n",
      "# files merged 420000\n",
      "# files merged 430000\n",
      "# files merged 440000\n",
      "# files merged 450000\n",
      "# files merged 460000\n",
      "# files merged 470000\n",
      "# files merged 480000\n",
      "# files merged 490000\n",
      "# files merged 500000\n",
      "# files merged 510000\n",
      "# files merged 520000\n",
      "# files merged 530000\n",
      "# files merged 540000\n"
     ]
    }
   ],
   "source": [
    "src_folder = \"/home/hdd_array0/batch6.2_xcp/batch6.2-cells-half299-hls07\"\n",
    "dst_folder = \"/home/hdd_array0/batch6.2_xcp/batch6.2-cells-half299\"\n",
    "addon = \"_hls07\"\n",
    "postfix = \".bmp\"\n",
    "\n",
    "# copy_and_addon(src_folder, dst_folder, addon, postfix)\n",
    "move_and_addon(src_folder, dst_folder, addon, postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.models import * \n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from multiprocessing import cpu_count\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 21\n",
    "nb_cpus = cpu_count()//2\n",
    "nb_gpus = 4\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '4, 5, 6, 7'\n",
    "\n",
    "image_size = (299, 299)\n",
    "input_shape= (299, 299, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 21)           20904509    lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Concatenate)           (None, 21)           0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "                                                                 model_1[3][0]                    \n",
      "                                                                 model_1[4][0]                    \n",
      "==================================================================================================\n",
      "Total params: 20,904,509\n",
      "Trainable params: 20,849,981\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    input_tensor = Input(input_shape)\n",
    "    x = Lambda(xception.preprocess_input)(input_tensor)\n",
    "\n",
    "    base_model = Xception(input_tensor=x, weights=None, include_top=False)\n",
    "    m_out = base_model.output\n",
    "    p_out = GlobalAveragePooling2D()(m_out)\n",
    "    p_out = Dropout(1.0)(p_out)\n",
    "    predictions = Dense(nb_classes, activation='softmax')(p_out)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "model = multi_gpu_model(model, gpus=nb_gpus)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('weights_008_0.0881.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44457 images belonging to 21 classes.\n",
      "695/695 [==============================] - 228s 328ms/step\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "test_path = \"/home/hdd_array0/batch6.2_xcp/batch6.2-cells-half299/valid\"\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "test_generator = gen.flow_from_directory(test_path, \n",
    "                                         target_size=image_size, \n",
    "                                         shuffle=False,\n",
    "                                         batch_size=batch_size)\n",
    "test_img_nums = test_generator.samples\n",
    "all_test_results = model.predict_generator(test_generator, \n",
    "                                           len(test_generator), \n",
    "                                           workers=nb_cpus, \n",
    "                                           use_multiprocessing=True,\n",
    "                                           verbose=1)\n",
    "all_labels = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GEC': 7, 'MC': 13, 'TRI': 19, 'LSIL_F': 12, 'PH': 14, 'SCC_G': 17, 'HSIL_M': 9, 'EC': 5, 'VIRUS': 20, 'ACTINO': 0, 'ASCUS': 3, 'RC': 15, 'HSIL_S': 10, 'AGC_A': 1, 'FUNGI': 6, 'LSIL_E': 11, 'AGC_B': 2, 'HSIL_B': 8, 'SCC_R': 18, 'SC': 16, 'CC': 4}\n"
     ]
    }
   ],
   "source": [
    "class_label_dict = test_generator.class_indices\n",
    "print(test_generator.class_indices)\n",
    "def get_key(dict_, value):\n",
    "    return [k for k, v in dict_.items() if v == value]\n",
    "\n",
    "# create class num lens dict, every dict store current class predict num\n",
    "total_predictions_dict = {}\n",
    "for row_class_name, label in class_label_dict.items():\n",
    "    total_predictions_dict[row_class_name] = {}\n",
    "    for column_class_name, label in class_label_dict.items():\n",
    "        total_predictions_dict[row_class_name][column_class_name] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresh = 0.95\n",
    "\n",
    "for i, label in enumerate(all_labels):\n",
    "    predict_index = np.argmax(all_test_results[i])\n",
    "    predict_det = all_test_results[i][predict_index]\n",
    "    if (predict_det > thresh):\n",
    "        # get the first result\n",
    "        label_class_name = get_key(class_label_dict, label)[0]\n",
    "        test_class_name = get_key(class_label_dict, np.argmax(all_test_results[i]))[0]\n",
    "#     print(label_class_name)\n",
    "#     print(total_predictions_dict[label_class_name].keys())\n",
    "        total_predictions_dict[label_class_name][test_class_name] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HSIL_S': 0, 'GEC': 22, 'MC': 0, 'LSIL_E': 0, 'PH': 0, 'SCC_G': 0, 'HSIL_M': 9, 'EC': 0, 'VIRUS': 0, 'TRI': 0, 'ASCUS': 0, 'RC': 1130, 'ACTINO': 0, 'AGC_A': 0, 'FUNGI': 0, 'LSIL_F': 0, 'AGC_B': 0, 'HSIL_B': 0, 'SCC_R': 0, 'SC': 0, 'CC': 0}\n"
     ]
    }
   ],
   "source": [
    "print(total_predictions_dict['RC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6189\n",
      "6189\n",
      "['GEC', 6083, 0, 0, 0, 0, 0, 1, 5, 10, 4, 9, 30, 5, 0, 0, 0, 13, 20, 0, 9, 0, '6189', 0.9829]\n",
      "6736\n",
      "6736\n",
      "['MC', 0, 6644, 0, 0, 89, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, '6736', 0.9863]\n",
      "33609\n",
      "33609\n",
      "['TRI', 0, 0, 33598, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0, '33609', 0.9997]\n",
      "1335\n",
      "1335\n",
      "['LSIL_F', 0, 0, 0, 1230, 0, 0, 0, 0, 0, 0, 93, 0, 12, 0, 0, 0, 0, 0, 0, 0, 0, '1335', 0.9213]\n",
      "6442\n",
      "6442\n",
      "['PH', 0, 87, 0, 0, 6312, 0, 0, 0, 0, 0, 22, 0, 0, 0, 8, 0, 0, 0, 0, 0, 13, '6442', 0.9798]\n",
      "3324\n",
      "3324\n",
      "['SCC_G', 4, 0, 0, 0, 0, 3065, 5, 0, 0, 0, 4, 0, 231, 12, 0, 0, 0, 0, 3, 0, 0, '3324', 0.9221]\n",
      "6119\n",
      "6119\n",
      "['HSIL_M', 4, 0, 0, 0, 0, 1, 6070, 0, 0, 0, 0, 0, 15, 0, 0, 0, 3, 26, 0, 0, 0, '6119', 0.992]\n",
      "747\n",
      "747\n",
      "['EC', 0, 0, 0, 0, 0, 0, 0, 736, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0, '747', 0.9853]\n",
      "5502\n",
      "5502\n",
      "['VIRUS', 0, 0, 0, 0, 0, 0, 1, 0, 5452, 0, 0, 0, 43, 0, 0, 0, 6, 0, 0, 0, 0, '5502', 0.9909]\n",
      "10982\n",
      "10982\n",
      "['ACTINO', 0, 0, 0, 0, 14, 0, 0, 0, 0, 10906, 0, 0, 4, 0, 4, 0, 0, 0, 0, 0, 54, '10982', 0.9931]\n",
      "6365\n",
      "6365\n",
      "['ASCUS', 0, 3, 0, 78, 15, 0, 0, 0, 0, 0, 6233, 0, 14, 0, 0, 22, 0, 0, 0, 0, 0, '6365', 0.9793]\n",
      "1161\n",
      "1161\n",
      "['RC', 22, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 1130, 0, 0, 0, 0, 0, 0, 0, 0, 0, '1161', 0.9733]\n",
      "32195\n",
      "32195\n",
      "['HSIL_S', 0, 0, 5, 0, 0, 139, 12, 0, 17, 0, 0, 0, 31503, 12, 0, 0, 0, 0, 0, 507, 0, '32195', 0.9785]\n",
      "3082\n",
      "3082\n",
      "['AGC_A', 2, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 7, 3065, 0, 0, 2, 0, 0, 0, 0, '3082', 0.9945]\n",
      "6267\n",
      "6267\n",
      "['FUNGI', 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 6249, 0, 0, 0, 0, 0, 12, '6267', 0.9971]\n",
      "3899\n",
      "3899\n",
      "['LSIL_E', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45, 0, 0, 0, 0, 3854, 0, 0, 0, 0, 0, '3899', 0.9885]\n",
      "1462\n",
      "1462\n",
      "['AGC_B', 8, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 2, 0, 6, 0, 0, 1438, 1, 0, 0, 0, '1462', 0.9836]\n",
      "3798\n",
      "3798\n",
      "['HSIL_B', 5, 0, 0, 0, 0, 0, 79, 0, 0, 0, 0, 0, 0, 4, 0, 0, 19, 3691, 0, 0, 0, '3798', 0.9718]\n",
      "5530\n",
      "5530\n",
      "['SCC_R', 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 5521, 0, 0, '5530', 0.9984]\n",
      "7667\n",
      "7667\n",
      "['SC', 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 734, 0, 0, 0, 0, 0, 0, 6929, 0, '7667', 0.9037]\n",
      "15342\n",
      "15342\n",
      "['CC', 1, 3, 0, 0, 3, 0, 0, 0, 0, 19, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 15313, '15342', 0.9981]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "out = open('confusion_matrix.csv','a', newline='')\n",
    "csv_write = csv.writer(out,dialect='excel')\n",
    "\n",
    "# write the title\n",
    "line = [class_name for class_name, label in class_label_dict.items()]\n",
    "line = [\" \"] + line + [\"TOTAL\"] + [\"ACC\"]\n",
    "csv_write.writerow(line)\n",
    "\n",
    "# write rows\n",
    "\n",
    "true_num = 0\n",
    "all_num = 0\n",
    "\n",
    "for row_class_name, label in class_label_dict.items():\n",
    "    one_class_total_predict = 0\n",
    "    line = [row_class_name]\n",
    "    for column_class_name, label in class_label_dict.items():\n",
    "        one_class_total_predict += total_predictions_dict[row_class_name][column_class_name]\n",
    "    \n",
    "    for column_class_name, label in class_label_dict.items():\n",
    "        one_class_cur_predict = total_predictions_dict[row_class_name][column_class_name]\n",
    "        # acc\n",
    "        #acc = round((one_class_cur_predict / one_class_total_predict), 4)\n",
    "        #line.append(str(acc))\n",
    "        # num\n",
    "        line.append(one_class_cur_predict)\n",
    "    print(one_class_total_predict)\n",
    "    print(str(one_class_total_predict))\n",
    "    line.append(str(one_class_total_predict))\n",
    "    line.append(round((total_predictions_dict[row_class_name][row_class_name] / one_class_total_predict), 4))       \n",
    "    print(line)\n",
    "    csv_write.writerow(line)\n",
    "    \n",
    "    true_num += total_predictions_dict[row_class_name][row_class_name]\n",
    "    all_num += one_class_total_predict\n",
    "    \n",
    "csv_write.writerow([\"ALL_ACC\"] + [round((true_num / all_num), 4)])\n",
    "    \n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

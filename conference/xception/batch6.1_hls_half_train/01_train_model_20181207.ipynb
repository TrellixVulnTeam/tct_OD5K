{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from multiprocessing import cpu_count\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 20\n",
    "nb_cpus = cpu_count()//2\n",
    "nb_gpus = 4\n",
    "\n",
    "image_size = (299, 299)\n",
    "input_shape= (299,299,3)\n",
    "\n",
    "train_path = \"/home/cnn/Documents/batch6.1/train5/train\"\n",
    "valid_path = \"/home/cnn/Documents/batch6.1/train5/valid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pretrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(input_shape)\n",
    "x = Lambda(xception.preprocess_input)(input_tensor)\n",
    "\n",
    "base_model = Xception(input_tensor=x, weights=None, include_top=False)\n",
    "m_out = base_model.output\n",
    "# m_out = SeparableConv2D(4096, kernel_size=3, strides=2)(m_out)\n",
    "# m_out = BatchNormalization()(m_out)\n",
    "p_out = GlobalAveragePooling2D()(m_out)\n",
    "p_out = Dropout(0.5)(p_out)\n",
    "predictions = Dense(nb_classes, activation='softmax', name=\"predictions\")(p_out)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "if nb_gpus > 1:\n",
    "    parallel_model = multi_gpu_model(model, gpus=nb_gpus)\n",
    "    \n",
    "optimizer = optimizers.SGD(lr=0.005, momentum=0.9, decay=0.0003)\n",
    "parallel_model.compile(optimizer=optimizer, \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights_train4_017.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen_t = ImageDataGenerator(rotation_range=30,                            \n",
    "                               width_shift_range=0.1,\n",
    "                               height_shift_range=0.1,\n",
    "                               zoom_range=0.1,\n",
    "                               brightness_range=[0.8, 1.2],\n",
    "                               horizontal_flip=True,\n",
    "                               vertical_flip=True)\n",
    "train_generator = img_gen_t.flow_from_directory(train_path, \n",
    "                                                target_size=image_size, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "img_gen_v = ImageDataGenerator()\n",
    "valid_generator = img_gen_v.flow_from_directory(valid_path,\n",
    "                                                target_size=image_size, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "parallel_model.fit_generator(generator=train_generator, \n",
    "                             steps_per_epoch=len(train_generator), \n",
    "                             epochs=epochs, \n",
    "                             verbose=1,\n",
    "                             validation_data=valid_generator, \n",
    "                             validation_steps=len(valid_generator), \n",
    "                             workers=nb_cpus, \n",
    "                             use_multiprocessing=True)\n",
    "\n",
    "model.save_weights(\"Xception_first_train.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 20)           20902460    lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Concatenate)       (None, 20)           0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "                                                                 model_1[3][0]                    \n",
      "                                                                 model_1[4][0]                    \n",
      "==================================================================================================\n",
      "Total params: 20,902,460\n",
      "Trainable params: 20,847,932\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "input_tensor = Input(input_shape)\n",
    "x = Lambda(xception.preprocess_input)(input_tensor)\n",
    "\n",
    "base_model = Xception(input_tensor=x, weights=None, include_top=False)\n",
    "m_out = base_model.output\n",
    "# m_out = SeparableConv2D(4096, kernel_size=3, strides=1)(m_out)\n",
    "# m_out = BatchNormalization()(m_out)\n",
    "p_out = GlobalAveragePooling2D()(m_out)\n",
    "p_out = Dropout(0.5)(p_out)\n",
    "predictions = Dense(nb_classes, activation='softmax', name=\"predictions\")(p_out)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "if nb_gpus > 1:\n",
    "    model = multi_gpu_model(model, gpus=nb_gpus)\n",
    "    \n",
    "optimizer = optimizers.SGD(lr=0.005, momentum=0.9, decay=0.0003)\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights_009_0.2320.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 913584 images belonging to 20 classes.\n",
      "Found 25362 images belonging to 20 classes.\n",
      "Epoch 4/100\n",
      "14274/14275 [============================>.] - ETA: 0s - loss: 0.1535 - acc: 0.9441\n",
      "14275/14275 [==============================] - 8322s 583ms/step - loss: 0.1535 - acc: 0.9441 - val_loss: 0.2314 - val_acc: 0.9447\n",
      "\n",
      "Epoch 00004: saving model to weights_004_0.2314.hdf5\n",
      "Epoch 5/100\n",
      "14275/14275 [==============================] - 8505s 596ms/step - loss: 0.1403 - acc: 0.9480 - val_loss: 0.3009 - val_acc: 0.9394\n",
      "\n",
      "Epoch 00005: saving model to weights_005_0.3009.hdf5\n",
      "Epoch 6/100\n",
      "14275/14275 [==============================] - 8269s 579ms/step - loss: 0.1373 - acc: 0.9492 - val_loss: 0.2668 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00006: saving model to weights_006_0.2668.hdf5\n",
      "Epoch 7/100\n",
      "14275/14275 [==============================] - 8418s 590ms/step - loss: 0.1351 - acc: 0.9498 - val_loss: 0.2899 - val_acc: 0.9401\n",
      "\n",
      "Epoch 00007: saving model to weights_007_0.2899.hdf5\n",
      "Epoch 8/100\n",
      "14274/14275 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9502\n",
      "Epoch 00007: saving model to weights_007_0.2899.hdf5\n",
      "14275/14275 [==============================] - 8172s 572ms/step - loss: 0.1345 - acc: 0.9502 - val_loss: 0.3299 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00008: saving model to weights_008_0.3299.hdf5\n",
      "Epoch 9/100\n",
      "14275/14275 [==============================] - 8271s 579ms/step - loss: 0.1342 - acc: 0.9502 - val_loss: 0.2658 - val_acc: 0.9422\n",
      "\n",
      "Epoch 00009: saving model to weights_009_0.2658.hdf5\n",
      "Epoch 10/100\n",
      "14275/14275 [==============================] - 8390s 588ms/step - loss: 0.1343 - acc: 0.9503 - val_loss: 0.2750 - val_acc: 0.9412\n",
      "\n",
      "Epoch 00010: saving model to weights_010_0.2750.hdf5\n",
      "Epoch 11/100\n",
      "    8/14275 [..............................] - ETA: 2:24:09 - loss: 0.1396 - acc: 0.9609"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "img_gen_t = ImageDataGenerator(rotation_range=30,                            \n",
    "                               width_shift_range=0.1,\n",
    "                               height_shift_range=0.1,\n",
    "                               zoom_range=0.1,\n",
    "                               brightness_range=[0.8, 1.2],\n",
    "                               horizontal_flip=True,\n",
    "                               vertical_flip=True)\n",
    "train_generator = img_gen_t.flow_from_directory(train_path, \n",
    "                                                target_size=image_size, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "img_gen_v = ImageDataGenerator()\n",
    "valid_generator = img_gen_v.flow_from_directory(valid_path,\n",
    "                                                target_size=image_size, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"weights_{epoch:03d}_{val_loss:.4f}.hdf5\", monitor='val_loss', verbose=1,\n",
    "                             save_best_only=False, save_weights_only=True, mode='min', period=1)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"./logs\", histogram_freq=0, batch_size=batch_size, write_graph=True, write_images=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.6, patience=1, min_lr=0.000001)\n",
    "\n",
    "callbacks = [checkpoint, tensorboard, reduce_lr]\n",
    "\n",
    "\n",
    "model.fit_generator(generator=train_generator, \n",
    "                    steps_per_epoch=len(train_generator), \n",
    "                    epochs=epochs, \n",
    "                    verbose=1,\n",
    "                    validation_data=valid_generator, \n",
    "                    validation_steps=len(valid_generator), \n",
    "                    callbacks=callbacks, \n",
    "                    workers=nb_cpus, \n",
    "                    use_multiprocessing=True,\n",
    "                    initial_epoch=3\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot training trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. first need to retrieve acc/loss/val_acc/val_loss info from tensorboard\n",
    "# in terminal: tensorboard --logdir ./logs\n",
    "# open browser with given link\n",
    "# save data to local csv and merge four separate files\n",
    "\n",
    "# 2. read from saved data csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv_file = \"./info_20181118.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "step = list(df.step)\n",
    "acc = list(df.acc)\n",
    "loss = list(df.loss)\n",
    "val_acc = list(df.val_acc)\n",
    "val_loss = list(df.val_loss)\n",
    "\n",
    "# 3. plot acc and loss\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "fig = plt.figure(1, figsize=(12,6), dpi=90)\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(step, acc,label=\"train\")\n",
    "ax.plot(step, val_acc,label=\"valid\")\n",
    "ax.legend()\n",
    "plt.title(\"training accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "ax = fig.add_subplot(122)\n",
    "ax.plot(step, loss,label=\"train\")\n",
    "ax.plot(step, val_loss,label=\"vaild\")\n",
    "ax.legend()\n",
    "plt.title(\"training loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

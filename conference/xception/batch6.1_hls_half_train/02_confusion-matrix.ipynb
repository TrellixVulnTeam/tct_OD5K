{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import * \n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from multiprocessing import cpu_count\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 20\n",
    "nb_cpus = cpu_count()//2\n",
    "nb_gpus = 4\n",
    "\n",
    "image_size = (299, 299)\n",
    "input_shape= (299, 299, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 299, 299, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 299, 299, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 299, 299, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 299, 299, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 20)           20902460    lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Concatenate)           (None, 20)           0           model_3[1][0]                    \n",
      "                                                                 model_3[2][0]                    \n",
      "                                                                 model_3[3][0]                    \n",
      "                                                                 model_3[4][0]                    \n",
      "==================================================================================================\n",
      "Total params: 20,902,460\n",
      "Trainable params: 20,847,932\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    input_tensor = Input(input_shape)\n",
    "    x = Lambda(xception.preprocess_input)(input_tensor)\n",
    "\n",
    "    base_model = Xception(input_tensor=x, weights=None, include_top=False)\n",
    "    m_out = base_model.output\n",
    "    p_out = GlobalAveragePooling2D()(m_out)\n",
    "    p_out = Dropout(1.0)(p_out)\n",
    "    predictions = Dense(nb_classes, activation='softmax')(p_out)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "model = multi_gpu_model(model, gpus=nb_gpus)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights_train5_010.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25362 images belonging to 20 classes.\n",
      "199/199 [==============================] - 108s 543ms/step\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "test_path = \"/home/cnn/Documents/batch6.1/train5/valid\"\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "test_generator = gen.flow_from_directory(test_path, \n",
    "                                         target_size=image_size, \n",
    "                                         shuffle=False,\n",
    "                                         batch_size=batch_size)\n",
    "test_img_nums = test_generator.samples\n",
    "all_test_results = model.predict_generator(test_generator, \n",
    "                                           len(test_generator), \n",
    "                                           workers=nb_cpus, \n",
    "                                           use_multiprocessing=True,\n",
    "                                           verbose=1)\n",
    "all_labels = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EC': 5, 'AGC_A': 1, 'ASCUS': 3, 'VIRUS': 19, 'LSIL_F': 12, 'SCC_R': 17, 'AGC_B': 2, 'SCC_G': 16, 'GEC': 7, 'RC': 14, 'MC': 13, 'HSIL_B': 8, 'CC': 4, 'ACTINO': 0, 'LSIL_E': 11, 'HSIL_M': 9, 'TRI': 18, 'FUNGI': 6, 'SC': 15, 'HSIL_S': 10}\n"
     ]
    }
   ],
   "source": [
    "class_label_dict = test_generator.class_indices\n",
    "print(test_generator.class_indices)\n",
    "def get_key(dict_, value):\n",
    "    return [k for k, v in dict_.items() if v == value]\n",
    "\n",
    "# create class num lens dict, every dict store current class predict num\n",
    "total_predictions_dict = {}\n",
    "for row_class_name, label in class_label_dict.items():\n",
    "    total_predictions_dict[row_class_name] = {}\n",
    "    for column_class_name, label in class_label_dict.items():\n",
    "        total_predictions_dict[row_class_name][column_class_name] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.0\n",
    "\n",
    "for i, label in enumerate(all_labels):\n",
    "    predict_index = np.argmax(all_test_results[i])\n",
    "    predict_det = all_test_results[i][predict_index]\n",
    "    if (predict_det > thresh):\n",
    "        # get the first result\n",
    "        label_class_name = get_key(class_label_dict, label)[0]\n",
    "        test_class_name = get_key(class_label_dict, np.argmax(all_test_results[i]))[0]\n",
    "#     print(label_class_name)\n",
    "#     print(total_predictions_dict[label_class_name].keys())\n",
    "        total_predictions_dict[label_class_name][test_class_name] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EC': 3, 'AGC_A': 0, 'ASCUS': 0, 'LSIL_F': 0, 'VIRUS': 0, 'SCC_R': 0, 'AGC_B': 0, 'SCC_G': 0, 'GEC': 7, 'HSIL_S': 0, 'RC': 282, 'ACTINO': 0, 'HSIL_B': 0, 'CC': 0, 'MC': 0, 'LSIL_E': 0, 'TRI': 0, 'HSIL_M': 0, 'SC': 0, 'FUNGI': 0}\n"
     ]
    }
   ],
   "source": [
    "print(total_predictions_dict['RC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465\n",
      "465\n",
      "['EC', 437, 0, 0, 0, 0, 0, 8, 0, 18, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, '465', 0.9398]\n",
      "1969\n",
      "1969\n",
      "['AGC_A', 0, 1912, 0, 0, 1, 0, 5, 17, 20, 0, 0, 10, 0, 0, 0, 4, 0, 0, 0, 0, '1969', 0.9711]\n",
      "3599\n",
      "3599\n",
      "['ASCUS', 0, 0, 3392, 1, 79, 0, 0, 1, 2, 0, 12, 0, 1, 0, 48, 4, 0, 0, 0, 59, '3599', 0.9425]\n",
      "2146\n",
      "2146\n",
      "['VIRUS', 0, 0, 0, 2116, 0, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 1, 0, 0, 5, 18, '2146', 0.986]\n",
      "840\n",
      "840\n",
      "['LSIL_F', 0, 0, 130, 0, 663, 0, 0, 4, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 40, '840', 0.7893]\n",
      "3598\n",
      "3598\n",
      "['SCC_R', 0, 0, 0, 0, 1, 3569, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 24, '3598', 0.9919]\n",
      "804\n",
      "804\n",
      "['AGC_B', 36, 11, 0, 0, 0, 0, 707, 0, 23, 1, 0, 14, 0, 0, 0, 12, 0, 0, 0, 0, '804', 0.8794]\n",
      "2066\n",
      "2066\n",
      "['SCC_G', 0, 3, 10, 0, 14, 11, 0, 1864, 17, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 143, '2066', 0.9022]\n",
      "3952\n",
      "3952\n",
      "['GEC', 8, 17, 6, 3, 1, 0, 16, 4, 3836, 14, 0, 20, 0, 3, 0, 14, 0, 0, 0, 10, '3952', 0.9706]\n",
      "292\n",
      "292\n",
      "['RC', 3, 0, 0, 0, 0, 0, 0, 0, 7, 282, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '292', 0.9658]\n",
      "6200\n",
      "6200\n",
      "['MC', 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 5941, 0, 54, 0, 4, 0, 0, 2, 0, 189, '6200', 0.9582]\n",
      "2353\n",
      "2353\n",
      "['HSIL_B', 7, 16, 0, 0, 0, 0, 18, 0, 17, 4, 0, 2254, 0, 0, 0, 33, 0, 0, 0, 4, '2353', 0.9579]\n",
      "10885\n",
      "10885\n",
      "['CC', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 0, 10375, 0, 0, 0, 0, 0, 0, 478, '10885', 0.9531]\n",
      "4791\n",
      "4791\n",
      "['ACTINO', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4760, 0, 0, 0, 0, 0, 31, '4791', 0.9935]\n",
      "2510\n",
      "2510\n",
      "['LSIL_E', 0, 0, 28, 0, 7, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2461, 0, 0, 1, 0, 12, '2510', 0.9805]\n",
      "3967\n",
      "3967\n",
      "['HSIL_M', 1, 15, 0, 1, 0, 0, 10, 5, 1, 0, 0, 28, 0, 0, 0, 3888, 0, 0, 0, 18, '3967', 0.9801]\n",
      "22430\n",
      "22430\n",
      "['TRI', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 22419, 0, 11, 0, '22430', 0.9995]\n",
      "3808\n",
      "3808\n",
      "['FUNGI', 0, 0, 0, 1, 1, 7, 0, 1, 0, 1, 12, 0, 0, 13, 0, 0, 0, 3768, 0, 4, '3808', 0.9895]\n",
      "2823\n",
      "2823\n",
      "['SC', 0, 0, 0, 19, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 16, 0, 2362, 423, '2823', 0.8367]\n",
      "11702\n",
      "11702\n",
      "['HSIL_S', 0, 4, 3, 12, 0, 11, 0, 67, 4, 0, 0, 0, 0, 0, 0, 8, 0, 0, 254, 11339, '11702', 0.969]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "out = open('confusion_matrix.csv','a', newline='')\n",
    "csv_write = csv.writer(out,dialect='excel')\n",
    "\n",
    "# write the title\n",
    "line = [class_name for class_name, label in class_label_dict.items()]\n",
    "line = [\" \"] + line + [\"TOTAL\"] + [\"ACC\"]\n",
    "csv_write.writerow(line)\n",
    "\n",
    "# write rows\n",
    "\n",
    "true_num = 0\n",
    "all_num = 0\n",
    "\n",
    "for row_class_name, label in class_label_dict.items():\n",
    "    one_class_total_predict = 0\n",
    "    line = [row_class_name]\n",
    "    for column_class_name, label in class_label_dict.items():\n",
    "        one_class_total_predict += total_predictions_dict[row_class_name][column_class_name]\n",
    "    \n",
    "    for column_class_name, label in class_label_dict.items():\n",
    "        one_class_cur_predict = total_predictions_dict[row_class_name][column_class_name]\n",
    "        # acc\n",
    "        #acc = round((one_class_cur_predict / one_class_total_predict), 4)\n",
    "        #line.append(str(acc))\n",
    "        # num\n",
    "        line.append(one_class_cur_predict)\n",
    "    print(one_class_total_predict)\n",
    "    print(str(one_class_total_predict))\n",
    "    line.append(str(one_class_total_predict))\n",
    "    line.append(round((total_predictions_dict[row_class_name][row_class_name] / one_class_total_predict), 4))       \n",
    "    print(line)\n",
    "    csv_write.writerow(line)\n",
    "    \n",
    "    true_num += total_predictions_dict[row_class_name][row_class_name]\n",
    "    all_num += one_class_total_predict\n",
    "    \n",
    "csv_write.writerow([\"ALL_ACC\"] + [round((true_num / all_num), 4)])\n",
    "    \n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from staintools import ReinhardNormalizer\n",
    "from staintools import MacenkoNormalizer\n",
    "from staintools import VahadaneNormalizer\n",
    "\n",
    "from staintools import standardize_brightness\n",
    "from staintools.utils.visual import read_image, show, show_colors, build_stack, patch_grid\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from multiprocessing import cpu_count\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed, wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_files(directory, prefix=None, postfix=None):\n",
    "    files_list = []\n",
    "    for root, sub_dirs, files in os.walk(directory):\n",
    "        for special_file in files:\n",
    "            if postfix:\n",
    "                if special_file.endswith(postfix):\n",
    "                    files_list.append(os.path.join(root, special_file))\n",
    "            elif prefix:\n",
    "                if special_file.startswith(prefix):\n",
    "                    files_list.append(os.path.join(root, special_file))\n",
    "            else:\n",
    "                files_list.append(os.path.join(root, special_file))\n",
    "    return files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(normalizer, image_in, save_dir, depth):\n",
    "    tokens = image_in.rsplit(os.sep, depth+1)\n",
    "    image_out = os.path.join(save_dir, *tokens[1:])\n",
    "    parent_dir = os.path.dirname(image_out)\n",
    "    os.makedirs(parent_dir, exist_ok=True)\n",
    "    r_img = read_image(image_in)\n",
    "    target = normalizer.transform(r_img)\n",
    "    target = cv2.cvtColor(target, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(image_out, target)\n",
    "    \n",
    "def batch_process_image(images_in, save_dir, depth):\n",
    "    normalizer = VahadaneNormalizer()\n",
    "    i1 = read_image(\"./lbp_pic/reference_pic/zs_abnormal.png\")\n",
    "    normalizer.fit(i1)\n",
    "    \n",
    "    for image_in in images_in:\n",
    "        process_image(normalizer, image_in, save_dir, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker:\n",
    "    def __init__(self, nb_workers):\n",
    "        self.executor = ProcessPoolExecutor(nb_workers)\n",
    "        self.futures = []\n",
    "        self.max_queue = nb_workers * 3\n",
    "        self.stoped = False\n",
    "\n",
    "#     def start_procs(self):\n",
    "#         for i in range(200000):\n",
    "#             while not self.stoped:\n",
    "#                 if len(self.futures) <= self.max_queue:\n",
    "#                     t = self.executor.submit(something_fancy)\n",
    "#                     t.add_done_callback(self.done)\n",
    "#                     self.futures.append(t)\n",
    "#                     break\n",
    "    \n",
    "    def add_process(self, *args):\n",
    "        while not self.stoped:\n",
    "            if len(self.futures) <= self.max_queue:\n",
    "                t = self.executor.submit(*args)\n",
    "#                 t.add_done_callback(self.done)\n",
    "                self.futures.append(t)\n",
    "                break\n",
    "\n",
    "    def done(self, future):\n",
    "        print(\"finished. result of calling process:\", future.result())\n",
    "        self.futures.remove(future)\n",
    "\n",
    "    def clear(self):\n",
    "        self.stoped = True\n",
    "#         for future in as_completed(self.futures):\n",
    "#             print(\"process cleared:\", future.result())\n",
    "        wait(self.futures)\n",
    "        print(\"processes cleared\")\n",
    "    \n",
    "    def start(self):\n",
    "        self.stoped = False\n",
    "        self.futures = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(input_dir, output_dir, depth):\n",
    "    images_in = scan_files(input_dir, postfix=\".jpg\")\n",
    "    print(\"total of {} images to process\".format(len(images_in)))\n",
    "    \n",
    "    worker = Worker(cpu_count()//2)\n",
    "    \n",
    "    batch_size = 2\n",
    "    queue_size = 0\n",
    "    for i in range(0, len(images_in), batch_size):\n",
    "        batch = images_in[i : i+batch_size].copy()\n",
    "        worker.add_process(batch_process_image, batch, output_dir, depth)\n",
    "        print(\"added {} - {} to process pool\".format(i, i+batch_size))\n",
    "        queue_size += 1\n",
    "        if queue_size == 10:\n",
    "            worker.clear()\n",
    "            worker.start()\n",
    "            queue_size = 0\n",
    "    \n",
    "    worker.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main(input_dir, output_dir, depth):\n",
    "#     images_in = scan_files(input_dir, postfix=\".jpg\")\n",
    "#     print(\"total of {} images to process\".format(len(images_in)))\n",
    "    \n",
    "#     executor = ProcessPoolExecutor(max_workers=cpu_count()-4)\n",
    "#     tasks = []\n",
    "    \n",
    "#     batch_size = 1000\n",
    "#     for i in range(0, len(images_in), batch_size):\n",
    "#         batch = images_in[i : i+batch_size]\n",
    "# #         batch_process_image(images_in=batch, save_dir=output_dir, depth=depth)\n",
    "#         tasks.append(executor.submit(batch_process_image, batch, output_dir, depth))\n",
    "#         print(\"added {} - {} to process pool\".format(i, i+batch_size))\n",
    "    \n",
    "#     job_count = len(tasks)\n",
    "#     for future in as_completed(tasks):\n",
    "#         job_count -= 1\n",
    "#         print(\"processed {} images, remaining job count: {}\".format(interval, job_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/home/nvme/ext_299\"\n",
    "output_dir = \"/home/nvme/ext_299_stained\"\n",
    "depth = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(input_dir, output_dir, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

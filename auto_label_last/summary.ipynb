{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel = pandas.read_excel(\"diagnosis.xlsx\")\n",
    "excel_dict = {}\n",
    "for index, row in excel.iterrows():\n",
    "    excel_dict[row[u'病理号'].encode(\"ascii\", \"ignore\")] = row[u'细胞学诊断'].encode(\"ascii\", \"ignore\")\n",
    "#print(excel_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "slides_path = \"slides_40_jpg\"\n",
    "slides = os.listdir(slides_path)\n",
    "classify_dict_all = []\n",
    "segment_dict_all = []\n",
    "for slide_i in slides:\n",
    "    slide_i_csv = os.path.join(slides_path, slide_i+\"/\"+slide_i+\".csv\")\n",
    "    csv_file = pandas.read_csv(slide_i_csv)\n",
    "    classify_dict = {\"ASCUS\":0, \"LSIL\":0, \"ASCH\":0, \"HSIL\":0, \"SCC\":0}\n",
    "    segment_dict = {\"ASCUS\":0, \"LSIL\":0, \"ASCH\":0, \"HSIL\":0, \"SCC\":0}\n",
    "    classify_dict[\"info\"] = (slide_i, excel_dict[slide_i])\n",
    "    segment_dict[\"info\"] = (slide_i, excel_dict[slide_i])\n",
    "    for index, row in csv_file.iterrows():\n",
    "        classify_dict[row[u'classify'].encode(\"ascii\", \"ignore\")] += 1\n",
    "        segment_dict[row[u'segment'].encode(\"ascii\", \"ignore\")] += 1\n",
    "    classify_dict_all.append(classify_dict)\n",
    "    segment_dict_all.append(segment_dict)\n",
    "    #print(classify_dict_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"diagnosis_output.csv\", \"w\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"slide_id\", \"diagnosis\", \n",
    "                     \"segment\", \"ASCUS\", \"LSIL\", \"ASCH\", \"HSIL\", \"SCC\", \n",
    "                     \"classify\", \"ASCUS\", \"LSIL\", \"ASCH\", \"HSIL\", \"SCC\"])\n",
    "    for segment, classify in zip(segment_dict_all, classify_dict_all):\n",
    "        writer.writerow([segment[\"info\"][0], segment[\"info\"][1], \n",
    "                         \"\", segment[\"ASCUS\"], segment[\"LSIL\"], segment[\"ASCH\"], segment[\"HSIL\"], segment[\"SCC\"],\n",
    "                         \"\", classify[\"ASCUS\"], classify[\"LSIL\"], classify[\"ASCH\"], classify[\"HSIL\"], classify[\"SCC\"]])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['x_y', 'segment', 'det', 'classify', 'det.1', 'xmin', 'ymin', 'xmax',\n",
      "       'ymax'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# separate test\n",
    "import os\n",
    "import csv\n",
    "import pandas\n",
    "csv_df = pandas.read_csv(\"csv_data/csv_file_0810/HSIL_csv/2017-11-24-13_19_06.csv\")\n",
    "print(csv_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"ASCUS\", \"LSIL\", \"ASCH\", \"HSIL\", \"SCC\"]\n",
    "header = ['class_i', \n",
    "\t\t  'ASCUS_s', 'LSIL_s', 'ASCH_s', 'HSIL_s', 'SCC_s', \n",
    "\t\t  'ASCUS_c', 'LSIL_c', 'ASCH_c', 'HSIL_c', 'SCC_c', \n",
    "\t\t  'ASCUS_c_09', 'LSIL_c_09', 'ASCH_c_09', 'HSIL_c_09', 'SCC_c_09', \n",
    "\t\t  'ASCUS_c_099', 'LSIL_c_099', 'ASCH_c_099', 'HSIL_c_099', 'SCC_c_099', \n",
    "\t\t  'ASCUS_c_0999', 'LSIL_c_0999', 'ASCH_c_0999', 'HSIL_c_0999', 'SCC_c_0999', \n",
    "\t\t  'w_mean', 'h_mean', 'v_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis = \"HSIL\"\n",
    "item_dict = {key:0 for key in header}\n",
    "# item_dict[\"class_i\"] = classes.index(diagnosis_dict[csv_file])\n",
    "item_dict[\"class_i\"] = classes.index(diagnosis)\n",
    "w_mean, h_mean, v_mean = 0.0, 0.0, 0.0\n",
    "for index,row in csv_df.iterrows():\n",
    "    item_dict[row['segment']+\"_s\"] += 1\n",
    "    item_dict[row['classify']+\"_c\"] += 1\n",
    "    if float(row['det.1']) > 0.9:\n",
    "        item_dict[row['classify']+\"_c_09\"] += 1\n",
    "    if float(row['det.1']) > 0.99:\n",
    "        item_dict[row['classify']+\"_c_099\"] += 1\n",
    "    if float(row['det.1']) > 0.999:\n",
    "        item_dict[row['classify']+\"_c_0999\"] += 1\n",
    "    w = float(row['xmax']) - float(row['xmin'])\n",
    "    h = float(row['ymax']) - float(row['ymin'])\n",
    "    w_mean += w\n",
    "    h_mean += h\n",
    "    v_mean += w * h\n",
    "item_dict['w_mean'] = w_mean / (index+1)\n",
    "item_dict['h_mean'] = h_mean / (index+1)\n",
    "item_dict['v_mean'] = v_mean / (index+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HSIL_c': 189, 'LSIL_c_099': 452, 'ASCUS_c_099': 24, 'SCC_c_09': 3, 'SCC_c_099': 2, 'ASCUS_c_0999': 12, 'h_mean': 159.09612985251795, 'HSIL_c_09': 158, 'LSIL_c_09': 635, 'HSIL_c_099': 130, 'LSIL_c_0999': 317, 'v_mean': 31342.91838047097, 'ASCH_c_0999': 0, 'w_mean': 159.11465666187064, 'ASCUS_c': 131, 'HSIL_c_0999': 89, 'ASCH_s': 41, 'ASCH_c': 7, 'ASCH_c_099': 0, 'class_i': 3, 'ASCUS_c_09': 60, 'ASCUS_s': 496, 'SCC_c_0999': 1, 'HSIL_s': 89, 'LSIL_s': 483, 'LSIL_c': 779, 'ASCH_c_09': 2, 'SCC_s': 3, 'SCC_c': 6}\n"
     ]
    }
   ],
   "source": [
    "print(item_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new test\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df = pd.read_csv(\"csv_data/used_in_changsha_conf/slides_40_csv/TC17005046.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104.4145054658102"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(csv_df['xmax'] - csv_df['xmin']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104.18521279030251"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(csv_df['ymax'] - csv_df['ymin']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.41450546581032 104.18521279030254 13659.65880368016\n"
     ]
    }
   ],
   "source": [
    "w_mean, h_mean, v_mean = 0.0, 0.0, 0.0\n",
    "for index,row in csv_df.iterrows():\n",
    "    w = float(row['xmax']) - float(row['xmin'])\n",
    "    h = float(row['ymax']) - float(row['ymin'])\n",
    "    w_mean += w\n",
    "    h_mean += h\n",
    "    v_mean += w * h\n",
    "print(w_mean /(index+1), h_mean /(index+1), v_mean/(index+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13659.658803680173"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((csv_df['xmax'] - csv_df['xmin'])*(csv_df['ymax'] - csv_df['ymin'])).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.66908000000001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(csv_df['xmax'] - csv_df['xmin']).quantile(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47.66908000000001, 56.798825, 68.58165260000001, 83.98520459999997, 97.57251000000002, 110.1668638, 120.94994059999999, 135.00262479999998, 162.06063220000007]\n"
     ]
    }
   ],
   "source": [
    "percentile = [x*0.1 for x in range(1, 10)]\n",
    "a = []\n",
    "w = csv_df['xmax'] - csv_df['xmin']\n",
    "for index, p in enumerate(percentile):\n",
    "    a.append(w.quantile(p))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.730303151548679"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.pow(0.5).quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "# from keras.models import * \n",
    "# from keras.layers import *\n",
    "# from keras.applications import *\n",
    "# from keras.preprocessing.image import *\n",
    "# from keras.utils.training_utils import multi_gpu_model\n",
    "# from multiprocessing import cpu_count\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 2\n",
    "image_size = (299, 299)\n",
    "input_shape= (299, 299, 3)\n",
    "\n",
    "nb_cpus = cpu_count()//2\n",
    "nb_gpus = 2\n",
    "\n",
    "train_path = \"/home/hdd0/Develop/immune/ext-data/data299/train/\"\n",
    "valid_path = \"/home/hdd0/Develop/immune/ext-data/data299/valid/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    input_tensor = tf.keras.Input(input_shape)\n",
    "    x = tf.keras.layers.Lambda(tf.keras.applications.xception.preprocess_input)(input_tensor)\n",
    "\n",
    "    base_model = tf.keras.applications.Xception(input_tensor=x, weights='imagenet', include_top=False)\n",
    "    m_out = base_model.output\n",
    "    p_out = tf.keras.layers.GlobalAveragePooling2D()(m_out)\n",
    "    p_out = tf.keras.layers.Dropout(0.5)(p_out)\n",
    "    predictions = tf.keras.layers.Dense(nb_classes, activation='softmax', name=\"predictions\")(p_out)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "if nb_gpus > 1:\n",
    "    parallel_model = tf.keras.utils.multi_gpu_model(model, gpus=nb_gpus)\n",
    "parallel_model.compile(optimizer='Adadelta', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# with tf.device('/cpu:0'):\n",
    "#     input_tensor = Input(input_shape)\n",
    "#     x = Lambda(xception.preprocess_input)(input_tensor)\n",
    "\n",
    "#     base_model = Xception(input_tensor=x, weights='imagenet', include_top=False)\n",
    "#     m_out = base_model.output\n",
    "#     p_out = GlobalAveragePooling2D()(m_out)\n",
    "#     p_out = Dropout(0.5)(p_out)\n",
    "#     predictions = Dense(nb_classes, activation='softmax', name=\"predictions\")(p_out)\n",
    "\n",
    "#     for layer in base_model.layers:\n",
    "#         layer.trainable = False\n",
    "\n",
    "#     model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# if nb_gpus > 1:\n",
    "#     parallel_model = multi_gpu_model(model, gpus=nb_gpus)\n",
    "# parallel_model.compile(optimizer='Adadelta', \n",
    "#               loss='categorical_crossentropy', \n",
    "#               metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen_t = ImageDataGenerator()\n",
    "train_generator = img_gen_t.flow_from_directory(train_path, \n",
    "                                                target_size=image_size, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "img_gen_v = ImageDataGenerator()\n",
    "valid_generator = img_gen_v.flow_from_directory(valid_path,\n",
    "                                                target_size=image_size, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "parallel_model.fit_generator(generator=train_generator, \n",
    "                             steps_per_epoch=len(train_generator), \n",
    "                             epochs=epochs, \n",
    "                             verbose=1,\n",
    "                             validation_data=valid_generator, \n",
    "                             validation_steps=len(valid_generator),\n",
    "                             workers=nb_cpus, \n",
    "                             use_multiprocessing=True)\n",
    "\n",
    "model.save_weights(\"Xception_first_train.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "import numpy as np\n",
    "\n",
    "num_samples = 32\n",
    "height = 224\n",
    "width = 224\n",
    "num_classes = 1000\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Xception(weights=None,input_shape=(height, width, 3),classes=num_classes)\n",
    "\n",
    "# Replicates the model on 2 GPUs.\n",
    "# This assumes that your machine has 2 available GPUs.\n",
    "parallel_model = multi_gpu_model(model, gpus=2)\n",
    "parallel_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "# Generate dummy data.\n",
    "x = np.random.random((num_samples, height, width, 3)).astype(np.float32)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "batch = iterator.get_next()\n",
    "\n",
    "y = parallel_model(batch)\n",
    "\n",
    "sess = tf.keras.backend.get_session()\n",
    "while True:\n",
    "    try:\n",
    "        result = sess.run(y)\n",
    "        print(result.shape)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I replaced the last section of your code\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "batch = iterator.get_next()\n",
    "\n",
    "y = parallel_model(batch)\n",
    "\n",
    "sess = tf.keras.backend.get_session()\n",
    "while True:\n",
    "    try:\n",
    "        result = sess.run(y)\n",
    "        print(result.shape)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        break\n",
    "        \n",
    "# with\n",
    "\n",
    "parallel_model.fit(dataset, steps_per_epoch=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
